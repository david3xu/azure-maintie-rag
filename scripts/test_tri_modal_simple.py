#!/usr/bin/env python3
"""
Simple Tri-Modal Search Test - Direct Implementation
"""

print("ğŸ¯ Tri-Modal Search Validation")
print("=" * 40)

# Test data
test_queries = [
    "How to deploy Azure ML models?",
    "What are compute options?",
    "How to monitor performance?"
]

knowledge_base = {
    "documents": [
        {
            "id": "doc1",
            "title": "Azure ML Deployment",
            "content": "Deploy models to endpoints, ACI, AKS containers",
            "keywords": ["deploy", "models", "endpoints", "containers"]
        },
        {
            "id": "doc2",
            "title": "Azure Compute Options",
            "content": "Compute Instances, Clusters for training and inference",
            "keywords": ["compute", "instances", "clusters", "training"]
        },
        {
            "id": "doc3",
            "title": "Model Monitoring",
            "content": "Monitor performance metrics, data drift, model accuracy",
            "keywords": ["monitor", "performance", "metrics", "accuracy"]
        }
    ]
}

def vector_search(query, docs):
    """Simple vector search simulation"""
    results = []
    query_words = query.lower().split()

    for doc in docs:
        score = 0
        for word in query_words:
            if any(word in keyword.lower() for keyword in doc["keywords"]):
                score += 1

        if score > 0:
            results.append({
                "doc_id": doc["id"],
                "title": doc["title"],
                "score": score,
                "mode": "vector"
            })

    return sorted(results, key=lambda x: x["score"], reverse=True)

def graph_search(query, docs):
    """Simple graph search simulation"""
    # Simulate entity relationships
    entity_map = {
        "deploy": ["models", "endpoints"],
        "compute": ["instances", "clusters"],
        "monitor": ["performance", "metrics"]
    }

    results = []
    query_words = query.lower().split()

    for doc in docs:
        relevance = 0
        for word in query_words:
            if word in entity_map:
                related_terms = entity_map[word]
                for term in related_terms:
                    if any(term in keyword.lower() for keyword in doc["keywords"]):
                        relevance += 1

        if relevance > 0:
            results.append({
                "doc_id": doc["id"],
                "title": doc["title"],
                "relevance": relevance,
                "mode": "graph"
            })

    return sorted(results, key=lambda x: x["relevance"], reverse=True)

def gnn_prediction(query, docs):
    """Simple GNN prediction simulation"""
    results = []

    for doc in docs:
        # Simulate ML prediction based on document features
        feature_score = len(doc["keywords"]) * 0.2
        content_score = len(doc["content"].split()) * 0.1
        prediction = min((feature_score + content_score) / 10, 1.0)

        results.append({
            "doc_id": doc["id"],
            "title": doc["title"],
            "prediction": round(prediction, 3),
            "mode": "gnn"
        })

    return sorted(results, key=lambda x: x["prediction"], reverse=True)

def tri_modal_fusion(query, docs):
    """Combine all three search modes"""
    vector_results = vector_search(query, docs)
    graph_results = graph_search(query, docs)
    gnn_results = gnn_prediction(query, docs)

    # Combine results
    fused = {}

    # Add vector scores
    for result in vector_results:
        doc_id = result["doc_id"]
        fused[doc_id] = {
            "doc_id": doc_id,
            "title": result["title"],
            "vector_score": result["score"],
            "graph_score": 0,
            "gnn_score": 0
        }

    # Add graph scores
    for result in graph_results:
        doc_id = result["doc_id"]
        if doc_id in fused:
            fused[doc_id]["graph_score"] = result["relevance"]
        else:
            fused[doc_id] = {
                "doc_id": doc_id,
                "title": result["title"],
                "vector_score": 0,
                "graph_score": result["relevance"],
                "gnn_score": 0
            }

    # Add GNN scores
    for result in gnn_results:
        doc_id = result["doc_id"]
        if doc_id in fused:
            fused[doc_id]["gnn_score"] = result["prediction"]
        else:
            fused[doc_id] = {
                "doc_id": doc_id,
                "title": result["title"],
                "vector_score": 0,
                "graph_score": 0,
                "gnn_score": result["prediction"]
            }

    # Calculate final scores
    final_results = []
    for doc_id, scores in fused.items():
        final_score = (
            scores["vector_score"] * 0.4 +
            scores["graph_score"] * 0.3 +
            scores["gnn_score"] * 0.3
        )

        scores["final_score"] = round(final_score, 3)
        final_results.append(scores)

    return sorted(final_results, key=lambda x: x["final_score"], reverse=True)

# Run tests
print("ğŸ§ª Testing tri-modal search integration...")

successful_tests = 0
total_tests = len(test_queries)

for i, query in enumerate(test_queries, 1):
    print(f"\nğŸ” Query {i}: '{query}'")

    try:
        # Test individual modes
        vector_res = vector_search(query, knowledge_base["documents"])
        graph_res = graph_search(query, knowledge_base["documents"])
        gnn_res = gnn_prediction(query, knowledge_base["documents"])

        # Test fusion
        fused_res = tri_modal_fusion(query, knowledge_base["documents"])

        print(f"  ğŸ” Vector: {len(vector_res)} results")
        print(f"  ğŸ•¸ï¸  Graph: {len(graph_res)} results")
        print(f"  ğŸ§  GNN: {len(gnn_res)} results")
        print(f"  ğŸ¯ Fused: {len(fused_res)} results")

        if fused_res:
            top_result = fused_res[0]
            print(f"  âœ… Top result: {top_result['title']} (score: {top_result['final_score']})")

        successful_tests += 1

    except Exception as e:
        print(f"  âŒ Test failed: {e}")

print(f"\n{'='*40}")
print(f"ğŸ“Š RESULTS: {successful_tests}/{total_tests} tests passed")

if successful_tests == total_tests:
    print("ğŸ‰ ALL TRI-MODAL TESTS PASSED!")
    print("\nâœ… Search Modes Validated:")
    print("  ğŸ” Vector Search: Keyword similarity")
    print("  ğŸ•¸ï¸  Graph Search: Entity relationships")
    print("  ğŸ§  GNN Prediction: ML relevance scoring")
    print("  ğŸ¯ Tri-Modal Fusion: Combined ranking")

    print("\nğŸš€ NEXT STEPS:")
    print("1. Configure real Azure services")
    print("2. Test with real Azure ML docs")
    print("3. Validate <3 second response times")
    print("4. Proceed to agent integration testing")
else:
    print("âš ï¸  SOME TESTS FAILED")
    print("Fix issues before proceeding")

print(f"\nğŸ“š Documentation:")
print("- Implementation Plan: docs/development/LOCAL_TESTING_IMPLEMENTATION_PLAN.md")
print("- Quick Start: docs/getting-started/QUICK_START.md")
