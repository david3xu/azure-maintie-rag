4.3 The Parsing Problem     179
4.3.2 Top-Down Parsers
A top-down parser traces or builds a parse tree in preorder. A preorder traversal 
of a parse tree begins with the root. Each node is visited before its branches are 
followed. Branches from a particular node are followed in left-to-right order. 
This corresponds to a leftmost derivation.
In terms of the derivation, a top-down parser can be described as follows: 
Given a sentential form that is part of a leftmost derivation, the parser’s task is 
to find the next sentential form in that leftmost derivation. The general form 
of a left sentential form is xA, whereby our notational conventions x is a string 
of terminal symbols, A is a nonterminal, and  is a mixed string. Because x 
contains only terminals, A is the leftmost nonterminal in the sentential form, 
so it is the one that must be expanded to get the next sentential form in a left-
most derivation. Determining the next sentential form is a matter of choosing 
the correct grammar rule that has A as its LHS. For example, if the current 
sentential form is
xA
and the A-rules are A → bB, A → cBb, and A → a, a top-down parser must 
choose among these three rules to get the next sentential form, which could 
be xbB, xcBb, or xa. This is the parsing decision problem for top-down 
parsers.
Different top-down parsing algorithms use different information to make 
parsing decisions. The most common top-down parsers choose the correct 
RHS for the leftmost nonterminal in the current sentential form by com-
paring the next token of input with the first symbols that can be generated 
by the RHSs of those rules. Whichever RHS has that token at the left end 
of the string it generates is the correct one. So, in the sentential form xA, 
the parser would use whatever token would be the first generated by A to 
determine which A-rule should be used to get the next sentential form. In 
the example above, the three RHSs of the A-rules all begin with different 
terminal symbols. The parser can easily choose the correct RHS based on 
the next token of input, which must be a, b, or c in this example. In general, 
choosing the correct RHS is not so straightforward, because some of the 
RHSs of the leftmost nonterminal in the current sentential form may begin 
with a nonterminal.
The most common top-down parsing algorithms are closely related. 
A recursive-descent parser is a coded version of a syntax analyzer based 
directly on the BNF description of the syntax of language. The most com-
mon alternative to recursive descent is to use a parsing table, rather than 
code, to implement the BNF rules. Both of these, which are called LL algo-
rithms, are equally powerful, meaning they work on the same subset of all 
context-free grammars. The first L in LL specifies a left-to-right scan of 
the input; the second L specifies that a leftmost derivation is generated. 
Section 4.4 introduces the recursive-descent approach to implementing an 
LL parser.
\n180     Chapter 4  Lexical and Syntax Analysis
4.3.3 Bottom-Up Parsers
A bottom-up parser constructs a parse tree by beginning at the leaves and 
progressing toward the root. This parse order corresponds to the reverse of a 
rightmost derivation. That is, the sentential forms of the derivation are pro-
duced in order of last to first. In terms of the derivation, a bottom-up parser 
can be described as follows: Given a right sentential form ,2 the parser must 
determine what substring of  is the RHS of the rule in the grammar that must 
be reduced to its LHS to produce the previous sentential form in the rightmost 
derivation. For example, the first step for a bottom-up parser is to determine 
which substring of the initial given sentence is the RHS to be reduced to its 
corresponding LHS to get the second last sentential form in the derivation. 
The process of finding the correct RHS to reduce is complicated by the fact 
that a given right sentential form may include more than one RHS from the 
grammar of the language being parsed. The correct RHS is called the 
handle.
Consider the following grammar and derivation:
S →aAc
A →aA   b
S => aAc => aaAc => aabc
A bottom-up parser of this sentence, aabc, starts with the sentence and must 
find the handle in it. In this example, this is an easy task, for the string contains 
only one RHS, b. When the parser replaces b with its LHS, A, it gets the sec-
ond to last sentential form in the derivation, aaAc. In the general case, as stated 
previously, finding the handle is much more difficult, because a sentential form 
may include several different RHSs.
A bottom-up parser finds the handle of a given right sentential form by 
examining the symbols on one or both sides of a possible handle. Symbols to 
the right of the possible handle are usually tokens in the input that have not 
yet been analyzed.
The most common bottom-up parsing algorithms are in the LR family, 
where the L specifies a left-to-right scan of the input and the R specifies that a 
rightmost derivation is generated.
4.3.4 The Complexity of Parsing
Parsing algorithms that work for any unambiguous grammar are complicated 
and inefficient. In fact, the complexity of such algorithms is O(n3), which means 
the amount of time they take is on the order of the cube of the length of the 
string to be parsed. This relatively large amount of time is required because 
these algorithms frequently must back up and reparse part of the sentence 
being analyzed. Reparsing is required when the parser has made a mistake in 
 
2. A right sentential form is a sentential form that appears in a rightmost derivation.
\n 4.4 Recursive-Descent Parsing     181
the parsing process. Backing up the parser also requires that part of the parse 
tree being constructed (or its trace) must be dismantled and rebuilt. O(n3) algo-
rithms are normally not useful for practical processes, such as syntax analysis for 
a compiler, because they are far too slow. In situations such as this, computer 
scientists often search for algorithms that are faster, though less general. Gen-
erality is traded for efficiency. In terms of parsing, faster algorithms have been 
found that work for only a subset of the set of all possible grammars. These 
algorithms are acceptable as long as the subset includes grammars that describe 
programming languages. (Actually, as discussed in Chapter 3, the whole class 
of context-free grammars is not adequate to describe all of the syntax of most 
programming languages.)
All algorithms used for the syntax analyzers of commercial compilers 
have complexity O(n), which means the time they take is linearly related to 
the length of the string to be parsed. This is vastly more efficient than O(n3) 
algorithms.
4.4 Recursive-Descent Parsing
This section introduces the recursive-descent top-down parser implementa-
tion process.
4.4.1 The Recursive-Descent Parsing Process
A recursive-descent parser is so named because it consists of a collection of 
subprograms, many of which are recursive, and it produces a parse tree in 
top-down order. This recursion is a reflection of the nature of programming 
languages, which include several different kinds of nested structures. For 
example, statements are often nested in other statements. Also, parentheses in 
expressions must be properly nested. The syntax of these structures is naturally 
described with recursive grammar rules.
EBNF is ideally suited for recursive-descent parsers. Recall from Chapter 
3 that the primary EBNF extensions are braces, which specify that what they 
enclose can appear zero or more times, and brackets, which specify that what 
they enclose can appear once or not at all. Note that in both cases, the enclosed 
symbols are optional. Consider the following examples:
<if_statement> → if <logic_expr> <statement> [else <statement>]
<ident_list> → ident {, ident}
In the first rule, the else clause of an if statement is optional. In the second, 
an <ident_list> is an identifier, followed by zero or more repetitions of a comma 
and an identifier.
A recursive-descent parser has a subprogram for each nonterminal in its 
associated grammar. The responsibility of the subprogram associated with 
a particular nonterminal is as follows: When given an input string, it traces 
\n182     Chapter 4  Lexical and Syntax Analysis
out the parse tree that can be rooted at that nonterminal and whose leaves 
match the input string. In effect, a recursive-descent parsing subprogram is 
a parser for the language (set of strings) that is generated by its associated 
nonterminal.
Consider the following EBNF description of simple arithmetic expressions:
<expr> → <term> {(+ | -) <term>}
<term> → <factor> {(* | /) <factor>}
<factor> → id | int_constant | ( <expr> )
Recall from Chapter 3 that an EBNF grammar for arithmetic expressions, such 
as this one, does not force any associativity rule. Therefore, when using such a 
grammar as the basis for a compiler, one must take care to ensure that the code 
generation process, which is normally driven by syntax analysis, produces code 
that adheres to the associativity rules of the language. This can easily be done 
when recursive-descent parsing is used.
In the following recursive-descent function, expr, the lexical analyzer is 
the function that is implemented in Section 4.2. It gets the next lexeme and puts 
its token code in the global variable nextToken. The token codes are defined 
as named constants, as in Section 4.2.
A recursive-descent subprogram for a rule with a single RHS is relatively 
simple. For each terminal symbol in the RHS, that terminal symbol is com-
pared with nextToken. If they do not match, it is a syntax error. If they match, 
the lexical analyzer is called to get the next input token. For each nonterminal, 
the parsing subprogram for that nonterminal is called.
The recursive-descent subprogram for the first rule in the previous exam-
ple grammar, written in C, is
/* expr
   Parses strings in the language generated by the rule:
   <expr> -> <term> {(+ | -) <term>}
   */
void expr() {
  printf("Enter <expr>\n");
/* Parse the first term */
  term();
/* As long as the next token is + or -, get
   the next token and parse the next term */
  while (nextToken == ADD_OP || nextToken == SUB_OP) {
    lex();
    term();
  }
  printf("Exit <expr>\n");
}  /* End of function expr */
\n 4.4 Recursive-Descent Parsing     183
Notice that the expr function includes tracing output statements, which are 
included to produce the example output shown later in this section.
Recursive-descent parsing subprograms are written with the convention 
that each one leaves the next token of input in nextToken. So, whenever 
a parsing function begins, it assumes that nextToken has the code for the 
leftmost token of the input that has not yet been used in the parsing process.
The part of the language that the expr function parses consists of one or 
more terms, separated by either plus or minus operators. This is the language 
generated by the nonterminal <expr>. Therefore, first it calls the function 
that parses terms (term). Then it continues to call that function as long as it 
finds ADD_OP or SUB_OP tokens (which it passes over by calling lex). This 
recursive-descent function is simpler than most, because its associated rule 
has only one RHS. Furthermore, it does not include any code for syntax error 
detection or recovery, because there are no detectable errors associated with 
the grammar rule.
A recursive-descent parsing subprogram for a nonterminal whose rule has 
more than one RHS begins with code to determine which RHS is to be parsed. 
Each RHS is examined (at compiler construction time) to determine the set of 
terminal symbols that can appear at the beginning of sentences it can generate. 
By matching these sets against the next token of input, the parser can choose 
the correct RHS.
The parsing subprogram for <term> is similar to that for <expr>:
/* term
   Parses strings in the language generated by the rule:
   <term> -> <factor> {(* | /) <factor>) 
   */
void term() {
  printf("Enter <term>\n");
/* Parse the first factor */
  factor();
/* As long as the next token is * or /, get the
   next token and parse the next factor */
  while (nextToken == MULT_OP || nextToken == DIV_OP) {
    lex();
    factor();
  }
  printf("Exit <term>\n");
}  /* End of function term */
The function for the <factor> nonterminal of our arithmetic expression 
grammar must choose between its two RHSs. It also includes error detection. 
In the function for <factor>, the reaction to detecting a syntax error is simply 
to call the error function. In a real parser, a diagnostic message must be 
\n184     Chapter 4  Lexical and Syntax Analysis
produced when an error is detected. Furthermore, parsers must recover from 
the error so that the parsing process can continue.
/* factor
   Parses strings in the language generated by the rule:
   <factor> -> id | int_constant | ( <expr )
   */
void factor() {
  printf("Enter <factor>\n");
/* Determine which RHS */
  if (nextToken == IDENT || nextToken == INT_LIT)
/* Get the next token */
    lex();
/* If the RHS is ( <expr>), call lex to pass over the 
   left parenthesis, call expr, and check for the right
   parenthesis */
  else {
    if (nextToken == LEFT_PAREN) {
      lex();
      expr();
      if (nextToken == RIGHT_PAREN)
        lex();
      else
        error();
    }  /* End of if (nextToken == ... */
/* It was not an id, an integer literal, or a left
   parenthesis */
    else
      error();
  }  /* End of else */
  printf("Exit <factor>\n");;
}  /* End of function factor */
Following is the trace of the parse of the example expression (sum + 47) / 
total, using the parsing functions expr, term, and factor, and the function 
lex from Section 4.2. Note that the parse begins by calling lex and the start 
symbol routine, in this case, expr.
Next token is: 25 Next lexeme is (
Enter <expr>
Enter <term>
Enter <factor>
\n 4.4 Recursive-Descent Parsing     185
Figure 4.2
Parse tree for 
(sum + 47) / total
sum
total
(
)
/
47
<factor>
<term>
<expr>
<factor>
<term>
<expr>
+
<term>
<factor>
<factor>
Next token is: 11 Next lexeme is sum
Enter <expr>
Enter <term>
Enter <factor>
Next token is: 21 Next lexeme is +
Exit <factor>
Exit <term>
Next token is: 10 Next lexeme is 47
Enter <term>
Enter <factor>
Next token is: 26 Next lexeme is )
Exit <factor>
Exit <term>
Exit <expr>
Next token is: 24 Next lexeme is /
Exit <factor>
Next token is: 11 Next lexeme is total
Enter <factor>
Next token is: -1 Next lexeme is EOF
Exit <factor>
Exit <term>
Exit <expr>
The parse tree traced by the parser for the preceding expression is shown in 
Figure 4.2.
\n186     Chapter 4  Lexical and Syntax Analysis
One more example grammar rule and parsing function should help solidify 
the reader’s understanding of recursive-descent parsing. Following is a gram-
matical description of the Java if statement:
<ifstmt> → if (<boolexpr>) <statement> [else <statement>]
The recursive-descent subprogram for this rule follows:
/* Function ifstmt
    Parses strings in the language generated by the rule:
    <ifstmt> -> if (<boolexpr>) <statement> 
                   [else <statement>]
    */
void ifstmt() {
/* Be sure the first token is 'if' */
  if (nextToken != IF_CODE)
    error();
  else {
/* Call lex to get to the next token */
    lex();
/* Check for the left parenthesis */
    if (nextToken != LEFT_PAREN)
      error();
    else {
/* Call boolexpr to parse the Boolean expression */
      boolexpr();
/* Check for the right parenthesis */
      if (nextToken != RIGHT_PAREN)
        error();
      else {
/* Call statement to parse the then clause */
        statement();
/* If an else is next, parse the else clause */
        if (nextToken == ELSE_CODE) {
/* Call lex to get over the else */
          lex();
          statement();
        } /* end of if (nextToken == ELSE_CODE ... */
      } /* end of else of if (nextToken != RIGHT ... */
    } /* end of else of if (nextToken != LEFT ... */
  } /* end of else of if (nextToken != IF_CODE ... */
} /* end of ifstmt */
Notice that this function uses parser functions for statements and Boolean 
expressions, which are not given in this section.
The objective of these examples is to convince you that a recursive-descent 
parser can be easily written if an appropriate grammar is available for the 
\n 4.4 Recursive-Descent Parsing     187
language. The characteristics of a grammar that allows a recursive-descent 
parser to be built are discussed in the following subsection.
4.4.2 The LL Grammar Class
Before choosing to use recursive descent as a parsing strategy for a compiler or 
other program analysis tool, one must consider the limitations of the approach, 
in terms of grammar restrictions. This section discusses these restrictions and 
their possible solutions.
One simple grammar characteristic that causes a catastrophic problem for 
LL parsers is left recursion. For example, consider the following rule:
A →A + B
A recursive-descent parser subprogram for A immediately calls itself to parse 
the first symbol in its RHS. That activation of the A parser subprogram then 
immediately calls itself again, and again, and so forth. It is easy to see that this 
leads nowhere (except to a stack overflow).
The left recursion in the rule A →A + B is called direct left recursion, 
because it occurs in one rule. Direct left recursion can be eliminated from a 
grammar by the following process:
For each nonterminal, A,
 
1. Group the A-rules as A →A1,  c  Am   1   2   c    n
where none of the >s begins with A
 
2. Replace the original A-rules with
A →1A   2A   c    nA
A →1A   2A   mA  	
Note that 	 specifies the empty string. A rule that has 	 as its RHS is called an 
erasure rule, because its use in a derivation effectively erases its LHS from the 
sentential form.
Consider the following example grammar and the application of the 
above process:
E →E + T   T
T →T *  F   F
F →(E)   id
For the E-rules, we have 1 = + T and  = T, so we replace the E-rules with
E →T E
E →+ T E   	
For the T-rules, we have 1 = * F and  = F, so we replace the T-rules with
T →F T
T →* F T   	
\n188     Chapter 4  Lexical and Syntax Analysis
Because there is no left recursion in the F-rules, they remain the same, so the 
complete replacement grammar is
E →T E
E →+ T E   	
T →F T
T →* F T   	
F →(E)   id
This grammar generates the same language as the original grammar but is not 
left recursive.
As was the case with the expression grammar written using EBNF in 
Section 4.4.1, this grammar does not specify left associativity of operators. 
However, it is relatively easy to design the code generation based on this 
grammar so that the addition and multiplication operators will have left 
associativity.
Indirect left recursion poses the same problem as direct left recursion. For 
example, suppose we have
A →B a A
B →A b
A recursive-descent parser for these rules would have the A subprogram imme-
diately call the subprogram for B, which immediately calls the A subprogram. 
So, the problem is the same as for direct left recursion. The problem of left 
recursion is not confined to the recursive-descent approach to building top-
down parsers. It is a problem for all top-down parsing algorithms. Fortunately, 
left recursion is not a problem for bottom-up parsing algorithms.
There is an algorithm to modify a given grammar to remove indirect left 
recursion (Aho et al., 2006), but it is not covered here. When writing a gram-
mar for a programming language, one can usually avoid including left recur-
sion, both direct and indirect.
Left recursion is not the only grammar trait that disallows top-down pars-
ing. Another is whether the parser can always choose the correct RHS on the 
basis of the next token of input, using only the first token generated by the 
leftmost nonterminal in the current sentential form. There is a relatively simple 
test of a non–left recursive grammar that indicates whether this can be done, 
called the pairwise disjointness test. This test requires the ability to compute 
a set based on the RHSs of a given nonterminal symbol in a grammar. These 
sets, which are called FIRST, are defined as
FIRST() = {a    => *  a} (If  => *  	, 	 is in FIRST())
in which =>* means 0 or more derivation steps.
An algorithm to compute FIRST for any mixed string  can be found in 
Aho et al. (2006). For our purposes, FIRST can usually be computed by inspec-
tion of the grammar.