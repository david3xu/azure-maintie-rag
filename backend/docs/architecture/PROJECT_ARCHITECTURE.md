# Azure Universal RAG System - Project Architecture

## Strategic Overview

The Azure Universal RAG system implements a revolutionary **tri-modal architecture** that breaks traditional RAG limitations through unified search capabilities, achieving 85-95% retrieval accuracy versus traditional RAG's 65-75%.

## Core Architecture

### Tri-Modal Search Architecture with Intelligent Agents
```
Query Input â†’ Intelligent Agent Reasoning â†’ Tri-Modal Orchestration
â”œâ”€â”€ Vector Search (Azure Cognitive Search) - Semantic similarity matching
â”œâ”€â”€ Knowledge Graph Traversal (Cosmos DB Gremlin) - Multi-hop relationship reasoning
â”œâ”€â”€ Graph Neural Network Enhancement (Azure ML) - Predictive pattern analysis
â””â”€â”€ Dynamic Tool Generation - Domain-specific tools discovered from data patterns
```

**Agent Intelligence Layer**: Data-driven agents that learn reasoning patterns from domain knowledge and orchestrate complex multi-step workflows using dynamically discovered tools.

### Performance Metrics
- **Query Response Time**: Sub-3 seconds (currently 0.8-1.8s)
- **Cache Hit Rate**: 60%+
- **Retrieval Accuracy**: 85-95% (enhanced by intelligent agent reasoning)
- **Multi-Step Reasoning**: Complex workflows solved in single agent session
- **Tool Discovery**: Dynamic tools generated from domain patterns in <5 seconds
- **Concurrent Users**: 100+ with auto-scaling
- **System Availability**: 99.9% target

## Design Principles

### 1. Unified Search Architecture with Agent Intelligence
- **Never fragment** the tri-modal approach - agents orchestrate, don't replace
- All agent tools must strengthen tri-modal search capabilities
- Agents perform complex reasoning while maintaining parallel processing using `asyncio.gather()`
- Dynamic tool discovery from learned domain patterns

### 2. Data-Driven Domain Architecture with Intelligent Agents
- **ALL domain knowledge derives from raw text data, not hardcoded configurations**
- Dynamic entity extraction, relationship learning, and pattern discovery
- **Agent reasoning patterns learned from domain data** - no hardcoded agent behaviors
- **Dynamic tool generation** from discovered action patterns in text corpus
- Zero manual configuration required for new domains
- Universal knowledge adaptation from any text corpus

### 3. Clean Architecture Implementation
```
API Layer (FastAPI) â†’ Services Layer â†’ Core Integration â†’ Infrastructure (Bicep)
```
- **Dependency Inversion**: Services depend on abstractions
- **Service Layer Boundaries**: API controllers never directly access Azure services
- **Testability**: All components mockable and testable

### 4. Performance-First Implementation
- Multi-level caching (memory + Redis fallback)
- Asynchronous I/O operations by default
- Real-time streaming with Server-Sent Events
- Progressive UI disclosure (user â†’ technical â†’ diagnostic layers)

### 5. Azure-Native Integration
- 9-service Azure integration with hybrid RBAC/API key authentication
- Bicep infrastructure as code with azd deployment
- Azure ML for GNN training and inference

## Technology Stack

### Backend
- **Framework**: FastAPI + Python 3.11+
- **Processing**: Async/await patterns with concurrent execution
- **Services**: Clean architecture with dependency injection

### Frontend
- **Framework**: React 19.1.0 + TypeScript
- **Streaming**: Server-Sent Events for real-time updates
- **UI Pattern**: Progressive disclosure with transparency layers

### Azure Services
- **Search**: Azure Cognitive Search (vector indexing)
- **Graph**: Cosmos DB Gremlin (knowledge relationships)
- **ML**: Azure ML (GNN training and inference)
- **Storage**: Blob Storage (document processing)
- **Additional**: Key Vault, Monitor, Functions, etc.

## Data-Driven Architecture Flow

```
Raw Text Data â†’ Dynamic Domain Discovery â†’ Universal Knowledge Generation:
â”œâ”€â”€ NLP Pipeline â†’ Entity/Relationship Extraction â†’ Learned Domain Patterns
â”œâ”€â”€ Vector Pipeline â†’ Semantic Embeddings â†’ Cognitive Search Index
â”œâ”€â”€ Graph Pipeline â†’ Knowledge Relationships â†’ Cosmos DB Gremlin
â””â”€â”€ GNN Pipeline â†’ Pattern Learning â†’ Azure ML Models
```

### Core Principle: **Raw Data In â†’ Intelligence Out**
- **Input**: Only raw text documents for any domain
- **Process**: Automated entity extraction, relationship discovery, pattern learning, agent reasoning discovery
- **Output**: Domain-specific knowledge graphs, search indices, GNN models, and intelligent agents with dynamic tools
- **Result**: Zero-configuration universal RAG with intelligent agent reasoning for any knowledge domain

## Agent Intelligence Architecture

### Data-Driven Agent Intelligence
The system includes intelligent agents that learn reasoning patterns directly from domain data, providing sophisticated problem-solving capabilities beyond traditional RAG systems.

### Agent Intelligence Layers
```
Raw Text Data â†’ Agent Pattern Discovery â†’ Dynamic Tool Generation â†’ Intelligent Reasoning
â”œâ”€â”€ Action Pattern Mining - Discover workflows from text
â”œâ”€â”€ Reasoning Chain Learning - Learn multi-step problem solving
â”œâ”€â”€ Tool Generation Pipeline - Create domain-specific tools
â””â”€â”€ Context-Aware Orchestration - Intelligent tri-modal coordination
```

### Universal Agent Capabilities

#### **1. Zero-Configuration Agent Deployment**
```python
# Medical Domain (from medical text data)
medical_agent = await UniversalAgent.create_from_domain("medical")
# Agent automatically learns: diagnose â†’ test â†’ prescribe â†’ monitor workflows

# Engineering Domain (from engineering manuals)  
engineering_agent = await UniversalAgent.create_from_domain("engineering")
# Agent automatically learns: troubleshoot â†’ inspect â†’ repair â†’ validate workflows

# Legal Domain (from legal documents)
legal_agent = await UniversalAgent.create_from_domain("legal") 
# Agent automatically learns: research â†’ analyze â†’ draft â†’ review workflows
```

#### **2. Dynamic Tool Discovery and Generation**
```python
class UniversalToolDiscovery:
    async def discover_tools_from_domain(self, learned_domain_config: LearnedDomainConfig):
        """Generate tools dynamically from discovered action patterns in text data"""
        
        # Extract action entities discovered from domain text corpus
        action_patterns = learned_domain_config.get_entities_by_type("action")
        
        # Generate tools for each discovered action pattern
        dynamic_tools = []
        for action_pattern in action_patterns:
            tool_definition = await self._generate_tool_from_action(
                action_name=action_pattern.name,
                context_patterns=action_pattern.learned_contexts,
                success_indicators=action_pattern.success_patterns,
                domain_knowledge=learned_domain_config
            )
            dynamic_tools.append(tool_definition)
        
        return DynamicToolRegistry(
            domain=learned_domain_config.domain_name,
            tools=dynamic_tools,
            learned_from_data=True
        )

# Example: Engineering domain discovers these actions from maintenance manuals:
discovered_actions = [
    "troubleshoot_vibration",    # Learned from "troubleshoot pump vibration" patterns
    "inspect_bearing",           # Learned from "inspect bearing condition" patterns  
    "replace_component",         # Learned from "replace damaged component" patterns
    "validate_repair"            # Learned from "validate repair completion" patterns
]
```

#### **3. Tri-Modal Agent Reasoning**
```python
class TriModalIntelligentAgent:
    async def solve_complex_query(self, query: str, domain: str):
        """Leverage tri-modal architecture for sophisticated reasoning"""
        
        # 1. Vector Search Intelligence - Semantic context discovery
        semantic_context = await self.vector_search.find_similar_contexts(
            query, domain, context_window=3
        )
        
        # 2. Knowledge Graph Reasoning - Multi-hop relationship traversal
        reasoning_path = await self.graph_traversal.explore_solution_paths(
            query_entities=self._extract_entities(query),
            target_goal=self._identify_goal(query),
            max_reasoning_hops=5,
            domain=domain
        )
        
        # 3. GNN Predictive Intelligence - Missing connection prediction
        predicted_solutions = await self.gnn_service.predict_solution_patterns(
            problem_context=query,
            reasoning_path=reasoning_path,
            domain=domain
        )
        
        # 4. Tool Selection and Orchestration
        relevant_tools = await self._select_tools_from_reasoning_path(
            reasoning_path, predicted_solutions, domain
        )
        
        # 5. Execute intelligent workflow
        solution = await self._execute_intelligent_workflow(
            semantic_context, reasoning_path, predicted_solutions, relevant_tools
        )
        
        return AgentSolutionResult(
            solution=solution,
            reasoning_chain=reasoning_path,
            confidence_score=predicted_solutions.confidence,
            tools_used=relevant_tools,
            tri_modal_synthesis=True
        )
```

#### **4. Multi-Step Intelligent Workflows**
```python
# Example: Complex engineering problem solving
query = "Pump is making unusual noise and vibrating excessively"

agent_reasoning_chain = [
    # Step 1: Semantic Analysis
    "Vector search identifies similar cases: bearing failure, misalignment, cavitation",
    
    # Step 2: Graph Reasoning  
    "Knowledge graph traversal: Pump â†’ has_component â†’ Bearing â†’ exhibits â†’ Vibration â†’ indicates â†’ Misalignment",
    
    # Step 3: GNN Prediction
    "Neural network predicts: 87% probability misalignment, 72% probability bearing wear",
    
    # Step 4: Tool Selection (learned from data)
    "Selected tools: inspect_alignment_tool, check_bearing_condition_tool, measure_vibration_tool",
    
    # Step 5: Solution Synthesis
    "Recommended workflow: 1) Check alignment, 2) Inspect bearings, 3) Measure vibration patterns, 4) Determine root cause"
]
```

### Agent Integration with Tri-Modal Architecture

#### **Enhanced Search Orchestration**
```python
class IntelligentSearchOrchestrator:
    async def execute_agent_enhanced_search(self, query: str, domain: str):
        """Agent-orchestrated tri-modal search with intelligent reasoning"""
        
        # Agent analyzes query and determines optimal search strategy
        search_strategy = await self.agent.analyze_query_intent(query, domain)
        
        # Parallel tri-modal search with agent intelligence
        if search_strategy.requires_multi_hop_reasoning:
            # Agent guides graph traversal for complex reasoning
            vector_task = self.vector_search.search(query, weights=search_strategy.vector_weights)
            graph_task = self.agent.guided_graph_reasoning(query, domain, hops=search_strategy.reasoning_depth)
            gnn_task = self.gnn_enhancer.predict_with_context(query, search_strategy.context)
        else:
            # Standard tri-modal search
            vector_task = self.vector_search.search(query)
            graph_task = self.graph_search.traverse(query)
            gnn_task = self.gnn_enhancer.predict(query)
        
        results = await asyncio.gather(vector_task, graph_task, gnn_task)
        
        # Agent synthesizes results with intelligent reasoning
        synthesized_result = await self.agent.synthesize_tri_modal_results(
            results, search_strategy, domain
        )
        
        return synthesized_result
```

### Agent Learning and Evolution

#### **Continuous Learning from Interactions**
```python
class AgentLearningSystem:
    async def learn_from_successful_interactions(self, interaction_log: InteractionLog):
        """Continuously improve agent reasoning from successful problem resolutions"""
        
        # Extract successful reasoning patterns
        successful_patterns = await self._extract_success_patterns(interaction_log)
        
        # Update domain knowledge with learned patterns
        updated_domain_config = await self._update_domain_patterns(
            domain=interaction_log.domain,
            new_patterns=successful_patterns
        )
        
        # Retrain GNN with new successful patterns
        await self._retrain_gnn_with_patterns(updated_domain_config)
        
        # Generate new tools from discovered patterns
        new_tools = await self._discover_new_tools_from_patterns(successful_patterns)
        
        return AgentEvolutionResult(
            patterns_learned=len(successful_patterns),
            tools_discovered=len(new_tools),
            domain_knowledge_enhanced=True
        )
```

### Agent Performance Advantages

#### **Beyond Traditional RAG Limitations**
- **Complex Problem Solving**: Multi-step reasoning chains instead of single query-response
- **Predictive Intelligence**: GNN-powered solution prediction based on learned patterns
- **Dynamic Adaptation**: Tools and reasoning patterns emerge from domain data
- **Context Awareness**: Maintains conversation context across multi-turn interactions
- **Workflow Orchestration**: Coordinates complex domain-specific workflows

#### **Competitive Differentiators**
- **Zero-Configuration Intelligence**: Agents automatically adapt to any domain from raw text
- **Tri-Modal Reasoning**: Combines semantic, graph, and neural intelligence
- **Dynamic Tool Ecosystem**: Domain-specific tools generated from data patterns
- **Predictive Problem Solving**: Solves problems not explicitly in training data
- **Universal Scalability**: Same agent architecture works across unlimited domains

## Development Guidelines

**ðŸ“‹ Mandatory References**: 
- **[CODING_STANDARDS.md](./CODING_STANDARDS.md)** - Mandatory coding rules for data-driven, production-ready implementation
- **[IMPLEMENTATION_ROADMAP.md](./IMPLEMENTATION_ROADMAP.md)** - Complete 12-week implementation plan and target architecture

**Core Development Requirements**:
- **Data-Driven Implementation**: No hardcoded values, learn from actual data
- **Production Reality**: No placeholders, fake data, or mock implementations  
- **Universal Scalability**: Domain-agnostic code that works with any raw text corpus
- **Performance Requirements**: Async-first, monitored, sub-3-second response times

## Architectural Design Rules for Implementation

### Rule 1: Tri-Modal Unity Principle
**Every feature must strengthen the unified search architecture**

```python
# âœ… CORRECT - Enhances tri-modal search
class UnifiedSearchOrchestrator:
    async def execute_search(self, query: str, domain: str):
        # Parallel execution of all three modalities
        vector_task = self.vector_search.search(query)
        graph_task = self.graph_search.traverse(query) 
        gnn_task = self.gnn_enhancer.predict(query)
        
        results = await asyncio.gather(vector_task, graph_task, gnn_task)
        return self.result_synthesizer.combine(results)

# âŒ INCORRECT - Creates competing search mechanism
class SimpleKeywordSearch:  # DON'T CREATE PARALLEL SEARCH SYSTEMS
    def search(self, keywords: List[str]):
        return basic_keyword_match(keywords)
```

### Rule 2: Data-Driven Domain Discovery
**All domain knowledge must be dynamically learned from raw text data**

```python
# âœ… CORRECT - Dynamic domain learning from data
class DataDrivenDomainService:
    async def process_raw_data(self, text_corpus: List[str], domain_name: str):
        # Extract entities dynamically from text
        discovered_entities = await self.nlp_service.extract_entities(text_corpus)
        
        # Learn relationship patterns from co-occurrence
        learned_relationships = await self.relationship_learner.discover_patterns(
            text_corpus, discovered_entities
        )
        
        # Generate domain configuration from learned patterns
        domain_config = DomainConfig(
            name=domain_name,
            entity_types=discovered_entities.types,
            relationship_patterns=learned_relationships.patterns,
            confidence_threshold=learned_relationships.confidence
        )
        
        return domain_config

class UniversalSearchService:
    async def process_query(self, query: str, domain: str):
        # Load domain patterns learned from data
        domain_config = await self.domain_registry.get_learned_patterns(domain)
        entities = await self.extract_entities(query, domain_config)
        
# âŒ INCORRECT - Hardcoded domain assumptions
class HardcodedDomainService:  # DON'T HARDCODE DOMAIN LOGIC
    MEDICAL_ENTITIES = ["patient", "diagnosis", "treatment"]  # HARDCODED
    
    async def process_query(self, query: str):
        if any(entity in query for entity in self.MEDICAL_ENTITIES):  # HARDCODED
            return self.medical_specific_logic(query)
```

### Rule 3: Async-First Performance Architecture
**All I/O operations must be asynchronous with parallel execution**

```python
# âœ… CORRECT - Async with parallel execution
class PerformanceOptimizedService:
    async def process_request(self, request: QueryRequest):
        # Parallel cache checks
        cache_tasks = [
            self.memory_cache.get(request.cache_key),
            self.redis_cache.get(request.cache_key),
            self.vector_cache.get(request.vector_key)
        ]
        
        cached_results = await asyncio.gather(*cache_tasks, return_exceptions=True)
        
        if not any(cached_results):
            # Parallel search execution
            search_results = await self.unified_search.execute_parallel(request)
            await self.update_caches(request, search_results)
            return search_results

# âŒ INCORRECT - Synchronous blocking operations
class BlockingService:  # DON'T BLOCK THE EVENT LOOP
    def process_request(self, request: QueryRequest):
        result1 = self.search_service.search(request)  # BLOCKING
        result2 = self.graph_service.traverse(request)  # BLOCKING
        return combine_results(result1, result2)
```

### Rule 4: Azure-Native Service Integration Pattern
**All Azure services must follow established connection and authentication patterns**

```python
# âœ… CORRECT - Standardized Azure integration
class AzureServiceBase:
    def __init__(self, config: AzureConfig):
        self.credential = DefaultAzureCredential()
        self.config = config
    
    async def get_authenticated_client(self, service_type: str):
        return self.client_factory.create(
            service_type, 
            self.config.endpoints[service_type],
            self.credential
        )

class SearchService(AzureServiceBase):
    async def initialize(self):
        self.search_client = await self.get_authenticated_client("cognitive_search")
        self.cosmos_client = await self.get_authenticated_client("cosmos_gremlin")
        self.ml_client = await self.get_authenticated_client("azure_ml")

# âŒ INCORRECT - Direct service instantiation
class DirectAzureService:  # DON'T BYPASS ESTABLISHED PATTERNS
    def __init__(self):
        # Direct instantiation - not following patterns
        self.search_client = SearchClient("endpoint", "key")  # WRONG
```

### Rule 5: Observable Enterprise Architecture
**All components must include comprehensive monitoring and error handling**

```python
# âœ… CORRECT - Enterprise observability
class ObservableService:
    def __init__(self, logger: Logger, metrics: MetricsCollector):
        self.logger = logger
        self.metrics = metrics
    
    @trace_operation("unified_search")
    async def execute_search(self, query: str) -> SearchResult:
        start_time = time.time()
        
        try:
            self.logger.info("Starting unified search", extra={"query_id": query.id})
            
            result = await self._perform_search(query)
            
            # Performance metrics
            duration = time.time() - start_time
            self.metrics.record_duration("search_duration", duration)
            self.metrics.increment("successful_searches")
            
            return result
            
        except Exception as e:
            self.logger.error(f"Search failed: {e}", extra={"query_id": query.id})
            self.metrics.increment("failed_searches")
            raise DomainException(f"Search execution failed") from e

# âŒ INCORRECT - No observability
class SilentService:  # DON'T CREATE SILENT FAILURES
    async def execute_search(self, query: str):
        try:
            return await self._search(query)  # NO LOGGING, NO METRICS
        except:
            return None  # SILENT FAILURE - WRONG
```

### Rule 6: Dependency Inversion and Testability
**All dependencies must be injected and components must be easily testable**

```python
# âœ… CORRECT - Dependency inversion with interfaces
from abc import ABC, abstractmethod

class SearchInterface(ABC):
    @abstractmethod
    async def search(self, query: str) -> SearchResult: ...

class GraphInterface(ABC):
    @abstractmethod
    async def traverse(self, entities: List[str]) -> GraphResult: ...

class UnifiedSearchService:
    def __init__(self, 
                 vector_search: SearchInterface,
                 graph_search: GraphInterface,
                 result_synthesizer: ResultSynthesizer):
        self.vector_search = vector_search
        self.graph_search = graph_search
        self.synthesizer = result_synthesizer

# Easy to test with mocks
@pytest.fixture
def mock_services():
    return {
        'vector_search': Mock(spec=SearchInterface),
        'graph_search': Mock(spec=GraphInterface),
        'synthesizer': Mock(spec=ResultSynthesizer)
    }

# âŒ INCORRECT - Hard dependencies
class TightlyCoupledService:  # DON'T CREATE TIGHT COUPLING
    def __init__(self):
        # Hard dependencies - can't test in isolation
        self.vector_search = AzureSearchClient("endpoint", "key")
        self.graph_search = CosmosGremlinClient("connection_string")
```

### Quality Gates for All Changes
1. **Unified Search Consistency**: Strengthens tri-modal architecture
2. **Domain Universality**: Works across any knowledge domain
3. **Performance Impact**: Supports sub-3-second processing targets
4. **Azure Integration**: Leverages established service patterns
5. **Enterprise Readiness**: Production-grade with monitoring
6. **Architectural Compliance**: Follows all 6 design rules above

### Critical Areas - Never Deviate
- **Unified Search**: Don't create parallel search mechanisms - agents orchestrate, don't replace
- **Data-Driven Domains**: Don't hardcode any domain-specific logic, configurations, or agent behaviors
- **Universal Architecture**: System must work with ANY raw text corpus without manual configuration
- **Dynamic Agent Intelligence**: Agent reasoning patterns and tools must be learned from data
- **Service Boundaries**: Don't bypass service layer abstractions
- **Performance Targets**: Don't compromise sub-3-second response times (including agent reasoning)
- **Azure Patterns**: Follow established authentication and connection patterns

### Service Layer Abstraction Rules

#### âœ… CORRECT Pattern - Respect Service Boundaries
```python
# API Controller (Good)
@router.post("/api/v1/query/universal")
async def universal_query(request: QueryRequest, service: SearchService = Depends()):
    result = await service.execute_unified_search(request.query, request.domain)
    return result

# Service Layer (Good)
class SearchService:
    def __init__(self, azure_client: AzureSearchClient):
        self._azure_client = azure_client
    
    async def execute_unified_search(self, query: str, domain: str):
        return await self._azure_client.search(query, domain)
```

#### âŒ INCORRECT Pattern - Bypassing Service Layer
```python
# API Controller (Bad - Direct Azure access)
@router.post("/api/v1/query/universal")
async def universal_query(request: QueryRequest):
    # DON'T DO THIS - bypasses service layer
    from azure.search.documents import SearchClient
    client = SearchClient(endpoint, index_name, credential)
    results = await client.search(request.query)
    return results
```

#### Service Layer Responsibilities
- **Business Logic**: Domain-specific processing and validation
- **Azure Service Coordination**: Orchestrate multiple Azure services
- **Error Handling**: Transform Azure exceptions to domain exceptions
- **Caching Strategy**: Implement multi-level caching logic
- **Performance Optimization**: Parallel processing coordination
- **Configuration Management**: Apply domain patterns and settings

#### API Layer Responsibilities (Controllers)
- **Request/Response Handling**: HTTP-specific concerns only
- **Authentication/Authorization**: Security validation
- **Input Validation**: Basic request format validation
- **Dependency Injection**: Inject services, never create them
- **Error Translation**: Convert service exceptions to HTTP responses

#### Abstraction Enforcement Rules
1. **No Direct Azure Imports in Controllers**: Controllers should only import service interfaces
2. **Service Dependency Injection**: Always inject services via DI container
3. **Interface-Based Design**: Services implement abstract interfaces for testability
4. **Configuration Isolation**: Azure connection strings/credentials only in service layer
5. **Error Boundary Respect**: Each layer handles appropriate error types

### Development Decision Framework
Before implementing features, evaluate:
1. Does this strengthen the tri-modal architecture?
2. **Can this work with ANY raw text data without manual configuration?**
3. Does this support performance targets?
4. Does this leverage Azure service patterns?
5. Is this enterprise-ready with proper monitoring?
6. **Does this respect service layer boundaries?**

### Universal Data-Driven Requirements
Every component must pass these tests:
1. **Zero Configuration Test**: Can it process a new domain's raw text without code changes?
2. **Domain Agnostic Test**: Does it avoid hardcoded entity types, relationship patterns, or agent behaviors?
3. **Dynamic Learning Test**: Does it discover patterns from data rather than assume them?
4. **Agent Intelligence Test**: Do agents learn reasoning patterns and generate tools from domain data?
5. **Tool Discovery Test**: Are tools dynamically generated from discovered action patterns in text?

## Layer Workflow Architecture

### **Correct Request Flow Pattern**

```mermaid
sequenceDiagram
    participant UI as ðŸŒ Frontend
    participant API as ðŸ“¡ API Layer
    participant SVC as ðŸ”§ Services Layer
    participant CORE as âš™ï¸ Core Integration
    participant AZ as â˜ï¸ Azure Services

    Note over UI,AZ: âœ… CORRECT: Clean layer separation with proper abstractions

    UI->>API: HTTP Request + Domain Context
    API->>API: Authentication & Input Validation
    API->>SVC: Business Domain Request via DI

    Note over SVC: Service Layer Orchestration
    SVC->>SVC: Apply domain patterns & caching logic
    SVC->>CORE: Azure Service Requests (parallel)
    
    par Parallel Azure Operations
        CORE->>AZ: Vector Search Request
    and
        CORE->>AZ: Graph Traversal Request  
    and
        CORE->>AZ: GNN Inference Request
    end
    
    AZ-->>CORE: Service Responses
    CORE-->>SVC: Unified Results
    SVC->>SVC: Result synthesis & caching
    SVC-->>API: Domain Response
    API->>API: HTTP Response formatting
    API-->>UI: JSON Response + Streaming Events
```

### **Layer Interaction Patterns**

#### âœ… **Pattern 1: Query Processing Workflow**
```python
# API Layer - HTTP concerns only
@router.post("/api/v1/query/universal")
async def universal_query(
    request: QueryRequest,
    query_service: QueryService = Depends(get_query_service)
) -> QueryResponse:
    try:
        # 1. Input validation (API layer responsibility)
        validated_request = validate_query_request(request)
        
        # 2. Delegate to service layer
        result = await query_service.process_universal_query(
            query=validated_request.query,
            domain=validated_request.domain,
            max_results=validated_request.max_results
        )
        
        # 3. HTTP response formatting (API layer responsibility)
        return QueryResponse(
            success=result.success,
            data=result.data,
            processing_time=result.processing_time
        )
        
    except ValidationError as e:
        # 4. HTTP error handling (API layer responsibility)
        raise HTTPException(status_code=400, detail=str(e))
    except ServiceException as e:
        # 5. Service error translation (API layer responsibility)
        raise HTTPException(status_code=500, detail="Query processing failed")

# Services Layer - Business logic orchestration
class QueryService:
    def __init__(self, search_client: SearchClient, cache_service: CacheService):
        self._search_client = search_client  # Core layer injection
        self._cache_service = cache_service
    
    async def process_universal_query(self, query: str, domain: str, max_results: int):
        # 1. Business logic - check cache first
        cache_key = self._generate_cache_key(query, domain)
        cached_result = await self._cache_service.get(cache_key)
        if cached_result:
            return cached_result
        
        # 2. Business logic - apply domain patterns
        domain_config = self._get_domain_config(domain)
        processed_query = self._apply_domain_patterns(query, domain_config)
        
        # 3. Coordinate core layer operations
        search_result = await self._search_client.unified_search(
            query=processed_query,
            domain=domain,
            max_results=max_results
        )
        
        # 4. Business logic - post-processing
        enhanced_result = self._enhance_with_domain_context(search_result, domain_config)
        
        # 5. Cache successful results
        await self._cache_service.set(cache_key, enhanced_result, ttl=300)
        
        return enhanced_result

# Core Layer - Azure service integration
class UnifiedSearchClient(AzureServiceBase):
    async def unified_search(self, query: str, domain: str, max_results: int):
        # 1. Parallel Azure service coordination
        vector_task = self._vector_search(query, max_results)
        graph_task = self._graph_search(query, domain, max_results)
        gnn_task = self._gnn_inference(query, domain)
        
        # 2. Execute in parallel
        results = await asyncio.gather(vector_task, graph_task, gnn_task)
        
        # 3. Core integration logic
        return self._synthesize_results(results)
```

#### âœ… **Pattern 2: Error Propagation Workflow**
```python
# Layer-appropriate error handling
class LayerErrorHandling:
    
    # Core Layer - Azure-specific errors
    class AzureServiceError(Exception):
        """Core layer exception for Azure service failures"""
        pass
    
    # Services Layer - Business logic errors  
    class BusinessLogicError(Exception):
        """Service layer exception for business rule violations"""
        pass
    
    # API Layer - HTTP-specific errors
    class APIValidationError(Exception):
        """API layer exception for request validation failures"""
        pass

# Error transformation at layer boundaries
class QueryService:
    async def process_query(self, query: str):
        try:
            # Core layer call
            return await self._search_client.search(query)
        except AzureServiceError as e:
            # Transform to service layer error
            raise BusinessLogicError(f"Search processing failed: {e}")
        except Exception as e:
            # Catch-all for unexpected errors
            raise BusinessLogicError(f"Unexpected error: {e}")

@router.post("/api/v1/query")  
async def query_endpoint(request: QueryRequest, service: QueryService = Depends()):
    try:
        return await service.process_query(request.query)
    except BusinessLogicError as e:
        # Transform to HTTP error
        raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        # Catch-all with generic HTTP response
        raise HTTPException(status_code=500, detail="Internal server error")
```

#### âœ… **Pattern 3: Caching Integration Workflow**
```python
# Multi-layer caching coordination
class CachingWorkflow:
    
    # Services Layer - Business logic caching
    class QueryService:
        async def process_query(self, query: str, domain: str):
            # 1. Service-level cache check (business logic results)
            service_cache_key = f"query:{query}:{domain}"
            cached_result = await self._cache_service.get(service_cache_key)
            if cached_result:
                return cached_result
            
            # 2. Delegate to core layer (which has its own caching)
            core_result = await self._search_client.search(query, domain)
            
            # 3. Service-level result enhancement
            enhanced_result = self._enhance_with_business_logic(core_result)
            
            # 4. Cache enhanced result at service layer
            await self._cache_service.set(service_cache_key, enhanced_result, ttl=300)
            return enhanced_result
    
    # Core Layer - Azure operation caching
    class SearchClient:
        async def search(self, query: str, domain: str):
            # 1. Core-level cache check (Azure operation results)
            core_cache_key = f"azure_search:{query}:{domain}"
            cached_result = await self._core_cache.get(core_cache_key)
            if cached_result:
                return cached_result
            
            # 2. Actual Azure service calls
            azure_result = await self._execute_azure_search(query, domain)
            
            # 3. Cache raw Azure results at core layer
            await self._core_cache.set(core_cache_key, azure_result, ttl=180)
            return azure_result
```

### **Layer Boundary Enforcement Rules**

#### **Data Flow Validation**
```python
# âœ… CORRECT - Data flows down through layers
@dataclass
class QueryRequest:      # API Layer model
    query: str
    domain: str

@dataclass  
class SearchRequest:     # Services Layer model (transformed)
    processed_query: str
    domain_config: DomainConfig
    cache_strategy: CacheStrategy

@dataclass
class AzureSearchRequest: # Core Layer model (Azure-specific)
    search_text: str
    index_name: str
    search_fields: List[str]

# âŒ INCORRECT - Never pass Azure-specific models up to API layer
def bad_endpoint() -> AzureSearchResult:  # DON'T DO THIS
    return azure_specific_result
```

#### **Dependency Direction Validation**
```python
# âœ… CORRECT - Dependencies point inward
class APIController:
    def __init__(self, service: SearchServiceInterface):  # Depends on service interface
        self._service = service

class SearchService:
    def __init__(self, client: SearchClientInterface):    # Depends on core interface  
        self._client = client

class SearchClient:
    def __init__(self, config: AzureConfig):              # Depends on config only
        self._config = config

# âŒ INCORRECT - Never let inner layers depend on outer layers
class SearchClient:
    def __init__(self, api_controller: APIController):    # DON'T DO THIS
        self._controller = api_controller
```

### **Performance Workflow Patterns**

#### **Parallel Processing Coordination**
```python
class PerformanceOptimizedWorkflow:
    
    # Services Layer - Business logic parallelization
    async def process_multiple_queries(self, queries: List[str], domain: str):
        # Parallel service-level processing
        query_tasks = [
            self.process_single_query(query, domain) 
            for query in queries
        ]
        return await asyncio.gather(*query_tasks, return_exceptions=True)
    
    # Core Layer - Azure service parallelization  
    async def unified_search(self, query: str, domain: str):
        # Parallel Azure service calls
        azure_tasks = [
            self._vector_search(query),
            self._graph_search(query, domain),
            self._gnn_inference(query, domain)
        ]
        results = await asyncio.gather(*azure_tasks, return_exceptions=True)
        return self._synthesize_results(results)
```

### **Monitoring and Observability Workflow**

#### **Cross-Layer Tracing**
```python
class ObservabilityWorkflow:
    
    # API Layer - Request-level tracing
    @trace_operation("api_query_request")
    async def query_endpoint(self, request: QueryRequest):
        with trace_context(request_id=request.id):
            return await self._service.process_query(request.query)
    
    # Services Layer - Business operation tracing
    @trace_operation("service_query_processing")  
    async def process_query(self, query: str):
        with business_context(query=query, domain=self._domain):
            return await self._client.search(query)
    
    # Core Layer - Azure operation tracing
    @trace_operation("azure_search_operation")
    async def search(self, query: str):
        with azure_context(service="cognitive_search", operation="search"):
            return await self._azure_client.search(query)
```

## Agent-Enhanced System Workflows

### **Intelligent Agent-Driven Query Processing Workflow**

The next-generation workflow that combines tri-modal search with intelligent agent reasoning:

```mermaid
sequenceDiagram
    participant USER as ðŸ‘¤ User
    participant AGENT as ðŸ¤– Intelligent Agent
    participant TOOLS as ðŸ”§ Dynamic Tools
    participant TRIMODAL as ðŸ” Tri-Modal Search
    participant LEARN as ðŸ“š Learning System

    Note over USER,LEARN: Agent-Enhanced Query Processing with Dynamic Tool Discovery

    USER->>AGENT: Complex Query (e.g., "Pump vibrating, need solution")
    AGENT->>AGENT: Analyze Query Intent & Complexity
    
    alt Simple Query
        AGENT->>TRIMODAL: Standard Tri-Modal Search
        TRIMODAL-->>AGENT: Search Results
    else Complex Problem-Solving Query
        AGENT->>AGENT: Extract Problem Context & Goals
        
        par Parallel Intelligence Gathering
            AGENT->>TRIMODAL: Semantic Context Discovery
        and
            AGENT->>TRIMODAL: Knowledge Graph Reasoning
        and  
            AGENT->>TRIMODAL: GNN Pattern Prediction
        end
        
        TRIMODAL-->>AGENT: Multi-Modal Intelligence Results
        
        AGENT->>AGENT: Synthesize Reasoning Chain
        Note over AGENT: Multi-hop reasoning:<br/>Pump â†’ Component â†’ Issue â†’ Solution
        
        AGENT->>TOOLS: Select Relevant Tools from Domain Registry
        Note over TOOLS: Tools discovered from domain data:<br/>inspect_vibration, check_alignment, measure_frequency
        
        AGENT->>TOOLS: Execute Tool Sequence
        TOOLS->>TRIMODAL: Tool-Guided Search Queries
        TRIMODAL-->>TOOLS: Domain-Specific Results
        TOOLS-->>AGENT: Tool Execution Results
        
        AGENT->>AGENT: Synthesize Complete Solution
    end
    
    AGENT-->>USER: Intelligent Solution with Reasoning Chain
    
    opt Successful Resolution
        AGENT->>LEARN: Record Successful Pattern
        LEARN->>LEARN: Extract New Tool Patterns
        LEARN->>TOOLS: Generate New Tools from Success
    end
```

#### **Agent-Enhanced Query Processing Code Pattern**
```python
class IntelligentAgentWorkflow:
    """Revolutionary agent-driven query processing with dynamic tool discovery"""
    
    async def process_intelligent_query(self, query: str, domain: str, user_session: UserSession):
        """Execute agent-enhanced query processing with learning"""
        
        # 1. Agent analyzes query complexity and intent
        query_analysis = await self.agent.analyze_query_intent(
            query=query,
            domain=domain,
            user_context=user_session.context
        )
        
        if query_analysis.complexity_level == "simple":
            # Standard tri-modal search for simple queries
            return await self._execute_standard_search(query, domain)
        
        # 2. Complex problem-solving workflow
        problem_context = await self.agent.extract_problem_context(
            query=query,
            domain_patterns=await self.domain_registry.get_learned_patterns(domain)
        )
        
        # 3. Parallel tri-modal intelligence gathering
        intelligence_tasks = [
            self._gather_semantic_context(query, domain, problem_context),
            self._perform_graph_reasoning(problem_context.entities, domain),
            self._predict_solution_patterns(problem_context, domain)
        ]
        
        semantic_context, reasoning_path, predictions = await asyncio.gather(
            *intelligence_tasks, return_exceptions=True
        )
        
        # 4. Agent synthesizes reasoning chain
        reasoning_chain = await self.agent.synthesize_reasoning_chain(
            semantic_context=semantic_context,
            graph_reasoning=reasoning_path,
            gnn_predictions=predictions,
            problem_context=problem_context
        )
        
        # 5. Dynamic tool selection and execution
        relevant_tools = await self.tool_registry.select_tools_for_problem(
            reasoning_chain=reasoning_chain,
            domain=domain,
            problem_type=problem_context.problem_type
        )
        
        # 6. Execute tool sequence with tri-modal support
        tool_results = await self._execute_tool_sequence(
            tools=relevant_tools,
            reasoning_chain=reasoning_chain,
            tri_modal_context={
                'semantic': semantic_context,
                'graph': reasoning_path,
                'predictions': predictions
            }
        )
        
        # 7. Agent synthesizes complete solution
        final_solution = await self.agent.synthesize_complete_solution(
            reasoning_chain=reasoning_chain,
            tool_results=tool_results,
            confidence_scores=predictions.confidence_scores
        )
        
        # 8. Learn from successful resolution
        if final_solution.success and user_session.feedback_positive:
            await self._learn_from_successful_resolution(
                query=query,
                domain=domain,
                reasoning_chain=reasoning_chain,
                successful_tools=relevant_tools,
                solution=final_solution
            )
        
        return AgentEnhancedResult(
            solution=final_solution,
            reasoning_chain=reasoning_chain,
            tools_used=relevant_tools,
            learning_occurred=True,
            processing_time=final_solution.processing_time,
            confidence_score=final_solution.confidence
        )
```

### **Dynamic Tool Discovery and Generation Workflow**

How the system continuously discovers and generates new tools from domain data and successful interactions:

```mermaid
flowchart TD
    subgraph "ðŸ“Š Data Analysis Layer"
        A[Raw Domain Text Corpus] --> B[Action Pattern Mining]
        B --> C[Workflow Sequence Detection]
        C --> D[Success Pattern Analysis]
        
        E[User Interaction Logs] --> F[Successful Resolution Analysis]
        F --> G[Tool Usage Pattern Mining]
        G --> D
    end
    
    subgraph "ðŸ” Pattern Discovery Engine"
        D --> H[Statistical Pattern Analysis]
        H --> I[Action-Outcome Correlation]
        I --> J[Tool Effectiveness Scoring]
        J --> K[New Tool Candidate Generation]
    end
    
    subgraph "ðŸ› ï¸ Tool Generation Pipeline"
        K --> L[Tool Template Generation]
        L --> M[Tri-Modal Integration Design]
        M --> N[Tool Validation Testing]
        N --> O{Tool Quality<br/>Score > 0.7?}
        
        O -->|Yes| P[Tool Registry Registration]
        O -->|No| Q[Pattern Refinement]
        Q --> K
    end
    
    subgraph "ðŸš€ Deployment & Learning"
        P --> R[Dynamic Tool Deployment]
        R --> S[A/B Testing with Users]
        S --> T[Performance Monitoring]
        T --> U[Continuous Improvement]
        U --> F
    end
    
    style A fill:#e1f5fe
    style P fill:#c8e6c9
    style R fill:#fff3e0
```

### **Agent Learning and Evolution Workflow**

How agents continuously improve their reasoning patterns and tool usage:

```mermaid
sequenceDiagram
    participant AGENT as ðŸ¤– Agent
    participant MONITOR as ðŸ“Š Performance Monitor
    participant LEARNER as ðŸ§  Learning Engine
    participant REGISTRY as ðŸ“š Knowledge Registry
    participant DEPLOY as ðŸš€ Deployment System

    Note over AGENT,DEPLOY: Continuous Agent Learning and Evolution

    loop Every Successful Resolution
        AGENT->>MONITOR: Report Resolution Success + Reasoning Chain
        MONITOR->>MONITOR: Analyze Resolution Effectiveness
        MONITOR->>LEARNER: Send Success Pattern Data
        
        LEARNER->>LEARNER: Extract Reasoning Patterns
        LEARNER->>LEARNER: Identify Tool Usage Patterns
        LEARNER->>LEARNER: Discover Optimization Opportunities
        
        LEARNER->>REGISTRY: Update Domain Knowledge
        LEARNER->>REGISTRY: Register New Reasoning Patterns
        
        opt Pattern Confidence > 0.8
            LEARNER->>DEPLOY: Deploy Enhanced Reasoning
            DEPLOY->>AGENT: Update Agent Intelligence
        end
    end
    
    loop Weekly Knowledge Synthesis
        LEARNER->>REGISTRY: Analyze Cross-Domain Patterns
        REGISTRY->>LEARNER: Provide Pattern Correlations
        
        LEARNER->>LEARNER: Synthesize Universal Patterns
        LEARNER->>DEPLOY: Deploy Cross-Domain Intelligence
        DEPLOY->>AGENT: Enhance Universal Reasoning
    end
```

## Critical System Workflows

### **Data-Driven Domain Discovery Workflow**

The universal architecture foundation - transforming any raw text data into domain-specific intelligence:

```mermaid
flowchart TD
    subgraph "ðŸ“„ Raw Data Input"
        A[Raw Text Corpus<br/>Any Domain] --> B[Data Validation<br/>Text Quality Check]
        B --> C[Blob Storage<br/>Domain Corpus]
    end
    
    subgraph "ðŸ” Dynamic Discovery Layer"
        C --> D1[NLP Entity Extraction<br/>Azure OpenAI]
        C --> D2[Relationship Discovery<br/>Co-occurrence Analysis]
        C --> D3[Pattern Recognition<br/>Statistical Analysis]
        
        D1 --> E1[Entity Types Discovery<br/>Automated Classification]
        D2 --> E2[Relationship Types Learning<br/>Pattern Mining]
        D3 --> E3[Domain Characteristics<br/>Feature Extraction]
    end
    
    subgraph "âš™ï¸ Configuration Generation"
        E1 --> F1[Generated Entity Schema]
        E2 --> F2[Generated Relationship Patterns]
        E3 --> F3[Generated Domain Config]
        
        F1 --> G[Dynamic Domain Registry<br/>Learned Configurations]
        F2 --> G
        F3 --> G
    end
    
    subgraph "ðŸ—ï¸ Knowledge Construction"
        G --> H1[Vector Index Generation<br/>Cognitive Search]
        G --> H2[Knowledge Graph Construction<br/>Cosmos DB Gremlin]
        G --> H3[GNN Model Training<br/>Azure ML PyTorch]
    end
    
    subgraph "âœ… Universal Readiness"
        H1 --> I[Tri-Modal System Ready<br/>Zero Configuration]
        H2 --> I
        H3 --> I
        I --> J[Domain-Agnostic Query Processing<br/>Any Text Corpus â†’ Intelligent Search]
    end
```

#### **Data-Driven Domain Discovery Code Pattern**
```python
class UniversalDomainDiscoveryWorkflow:
    """Transforms any raw text corpus into domain-specific intelligence"""
    
    async def discover_and_build_domain(self, raw_text_corpus: List[str], domain_name: str):
        """Execute complete data-driven domain discovery and system building"""
        
        # 1. Raw data ingestion (no assumptions about domain)
        validated_corpus = await self._validate_text_corpus(raw_text_corpus)
        storage_path = await self._upload_raw_corpus(validated_corpus, domain_name)
        
        # 2. Dynamic discovery pipeline (learn from data)
        discovery_tasks = [
            self._discover_entities(validated_corpus),           # What entities exist?
            self._discover_relationships(validated_corpus),      # How do they relate?
            self._discover_patterns(validated_corpus)            # What are the patterns?
        ]
        
        entities, relationships, patterns = await asyncio.gather(
            *discovery_tasks, return_exceptions=True
        )
        
        # 3. Generate domain configuration from discoveries
        learned_domain_config = await self._generate_domain_config(
            domain_name=domain_name,
            discovered_entities=entities,
            learned_relationships=relationships,
            statistical_patterns=patterns
        )
        
        # 4. Build tri-modal system using learned configuration
        system_build_tasks = [
            self._build_vector_index(validated_corpus, learned_domain_config),
            self._build_knowledge_graph(entities, relationships, learned_domain_config),
            self._train_gnn_model(entities, relationships, learned_domain_config)
        ]
        
        vector_system, graph_system, gnn_system = await asyncio.gather(
            *system_build_tasks, return_exceptions=True
        )
        
        # 5. Register learned domain in universal system
        domain_registration = await self._register_learned_domain(
            domain_name=domain_name,
            domain_config=learned_domain_config,
            system_components={
                'vector_index': vector_system,
                'knowledge_graph': graph_system,
                'gnn_model': gnn_system
            }
        )
        
        return UniversalDomainResult(
            success=domain_registration.success,
            domain_name=domain_name,
            entities_discovered=len(entities),
            relationships_learned=len(relationships),
            patterns_identified=len(patterns),
            tri_modal_ready=all([vector_system, graph_system, gnn_system]),
            zero_configuration_achieved=True
        )

    async def _discover_entities(self, text_corpus: List[str]):
        """Discover entity types from raw text using NLP"""
        discovered_entities = []
        
        for text in text_corpus:
            # Use Azure OpenAI for entity extraction (no predefined types)
            entities = await self.openai_service.extract_entities(
                text=text,
                instruction="Extract all meaningful entities without predefined categories"
            )
            discovered_entities.extend(entities)
        
        # Statistical analysis to identify entity type patterns
        entity_clusters = await self._cluster_entities_by_similarity(discovered_entities)
        entity_types = await self._generate_entity_type_names(entity_clusters)
        
        return EntityDiscoveryResult(
            raw_entities=discovered_entities,
            discovered_types=entity_types,
            type_confidence=entity_clusters.confidence_scores
        )

    async def _discover_relationships(self, text_corpus: List[str]):
        """Learn relationship patterns from text co-occurrence"""
        relationship_candidates = []
        
        for text in text_corpus:
            # Extract potential relationships using dependency parsing
            relations = await self.nlp_service.extract_dependency_relations(text)
            relationship_candidates.extend(relations)
        
        # Statistical pattern mining to identify significant relationships
        significant_patterns = await self._mine_relationship_patterns(relationship_candidates)
        relationship_types = await self._classify_relationship_types(significant_patterns)
        
        return RelationshipDiscoveryResult(
            raw_relations=relationship_candidates,
            learned_patterns=significant_patterns,
            relationship_types=relationship_types
        )
        
    async def _generate_domain_config(self, domain_name: str, discovered_entities, 
                                    learned_relationships, statistical_patterns):
        """Generate domain configuration from learned patterns"""
        return LearnedDomainConfig(
            domain_name=domain_name,
            entity_types=discovered_entities.discovered_types,
            relationship_types=learned_relationships.relationship_types,
            vector_weights=statistical_patterns.feature_weights,
            gnn_model_params=statistical_patterns.graph_characteristics,
            confidence_threshold=min(
                discovered_entities.type_confidence,
                learned_relationships.pattern_confidence
            )
        )
```

### **Model Training and Deployment Workflow**

How the system learns and evolves:

```mermaid
sequenceDiagram
    participant DW as ðŸ“Š Data Workflow
    participant ML as ðŸ§  ML Service  
    participant AzML as â˜ï¸ Azure ML
    participant REG as ðŸ“¦ Model Registry
    participant CORE as âš™ï¸ Core Services

    Note over DW,CORE: GNN Training and Deployment Pipeline

    DW->>ML: Graph data ready for training
    ML->>ML: Prepare PyTorch Geometric dataset
    ML->>AzML: Submit training job (GPU compute)
    
    Note over AzML: Training Process (5-15 minutes)
    AzML->>AzML: Node classification training
    AzML->>AzML: Validation and metrics
    
    AzML-->>ML: Training completed (model + metrics)
    ML->>ML: Validate model performance
    
    alt Model meets accuracy threshold (>55%)
        ML->>REG: Register validated model
        REG-->>ML: Model version registered
        ML->>CORE: Update model reference
        CORE->>CORE: Load new model for inference
        Note over CORE: Model deployment successful
    else Model below threshold
        ML->>ML: Log training failure
        Note over ML: Keep previous model active
    end
```

#### **Model Training Code Pattern**
```python
class ModelTrainingWorkflow:
    """Manages GNN model training and deployment lifecycle"""
    
    async def train_gnn_model(self, graph_data: GraphData, domain: str):
        """Complete GNN training pipeline"""
        
        # 1. Data preparation
        training_data = await self._prepare_pytorch_geometric_data(graph_data)
        
        # 2. Submit Azure ML training job
        training_job = await self._submit_training_job(training_data, domain)
        
        # 3. Monitor training progress
        model_metrics = await self._monitor_training(training_job.id)
        
        # 4. Validate trained model
        if model_metrics.accuracy >= self.ACCURACY_THRESHOLD:
            # 5. Register and deploy model
            model_version = await self._register_model(training_job, model_metrics)
            await self._deploy_model(model_version, domain)
            
            return TrainingResult(
                success=True,
                model_version=model_version,
                accuracy=model_metrics.accuracy,
                training_time=model_metrics.duration
            )
        else:
            return TrainingResult(
                success=False,
                error=f"Model accuracy {model_metrics.accuracy} below threshold {self.ACCURACY_THRESHOLD}"
            )
```

### **System Initialization Workflow**

How services start up with proper dependency resolution:

```mermaid
flowchart TD
    subgraph "ðŸš€ Application Startup"
        A[FastAPI App Start] --> B[Load Configuration]
        B --> C[Initialize DI Container]
    end
    
    subgraph "ðŸ” Azure Authentication"
        C --> D[Azure Credential Setup]
        D --> E[Service Principal Auth]
        E --> F[Managed Identity Fallback]
    end
    
    subgraph "âš™ï¸ Service Initialization"
        F --> G1[Infrastructure Service]
        F --> G2[Cache Service]
        F --> G3[Performance Service]
        
        G1 --> H1[Azure OpenAI Client]
        G1 --> H2[Cognitive Search Client]
        G1 --> H3[Cosmos DB Client]
        G1 --> H4[Azure ML Client]
        G1 --> H5[Blob Storage Client]
    end
    
    subgraph "âœ… Health Validation"
        H1 --> I[Service Health Checks]
        H2 --> I
        H3 --> I
        H4 --> I
        H5 --> I
        
        I --> J{All Services<br/>Healthy?}
        J -->|Yes| K[App Ready State]
        J -->|No| L[Graceful Degradation]
    end
```

#### **System Initialization Code Pattern**
```python
class SystemInitializationWorkflow:
    """Manages application startup and service initialization"""
    
    async def initialize_application(self):
        """Complete application initialization workflow"""
        
        # 1. Configuration loading
        config = await self._load_configuration()
        
        # 2. Dependency injection container setup
        container = await self._setup_di_container(config)
        
        # 3. Azure authentication
        credentials = await self._setup_azure_authentication(config)
        
        # 4. Core service initialization (parallel)
        services = await self._initialize_core_services(credentials, config)
        
        # 5. Health validation
        health_status = await self._validate_service_health(services)
        
        if health_status.all_healthy:
            return InitializationResult(
                success=True,
                services_initialized=len(services),
                startup_time=health_status.total_time
            )
        else:
            # Graceful degradation
            return await self._handle_partial_initialization(health_status)

    async def _initialize_core_services(self, credentials, config):
        """Initialize all Azure services in parallel"""
        initialization_tasks = [
            self._init_openai_service(credentials, config),
            self._init_search_service(credentials, config),
            self._init_cosmos_service(credentials, config),
            self._init_ml_service(credentials, config),
            self._init_storage_service(credentials, config)
        ]
        
        services = await asyncio.gather(*initialization_tasks, return_exceptions=True)
        
        # Filter successful initializations
        healthy_services = [s for s in services if not isinstance(s, Exception)]
        
        return healthy_services
```

### **Configuration Management Workflow**

How domain-agnostic design works in practice:

```mermaid
flowchart LR
    subgraph "ðŸ“ Configuration Sources"
        A[Environment Variables]
        B[Domain Patterns File]
        C[Azure Key Vault]
        D[Runtime Parameters]
    end
    
    subgraph "ðŸ”„ Configuration Processing"
        A --> E[Configuration Merger]
        B --> E
        C --> E
        D --> E
        
        E --> F[Domain Pattern Resolver]
        F --> G[Environment Validator]
        G --> H[Configuration Cache]
    end
    
    subgraph "ðŸŽ¯ Application Layers"
        H --> I[API Layer Config]
        H --> J[Services Layer Config] 
        H --> K[Core Layer Config]
        
        I --> L[HTTP Settings]
        J --> M[Business Rules]
        K --> N[Azure Connections]
    end
```

#### **Configuration Management Code Pattern**
```python
class ConfigurationWorkflow:
    """Manages domain-agnostic configuration loading and application"""
    
    async def load_domain_configuration(self, domain: str, environment: str):
        """Load and merge configuration for specific domain and environment"""
        
        # 1. Load base configuration
        base_config = await self._load_base_configuration(environment)
        
        # 2. Load domain-specific patterns
        domain_patterns = await self._load_domain_patterns(domain)
        
        # 3. Load sensitive configuration from Key Vault
        secrets = await self._load_azure_secrets(environment)
        
        # 4. Merge configurations with precedence
        merged_config = self._merge_configurations(
            base_config, domain_patterns, secrets
        )
        
        # 5. Validate configuration completeness
        validation_result = await self._validate_configuration(merged_config)
        
        if validation_result.is_valid:
            # 6. Apply to application layers
            await self._apply_configuration(merged_config)
            
            return ConfigurationResult(
                success=True,
                domain=domain,
                environment=environment,
                loaded_patterns=len(domain_patterns.entity_types),
                azure_services=len(merged_config.azure_services)
            )
        else:
            raise ConfigurationError(f"Invalid configuration: {validation_result.errors}")

    def _merge_configurations(self, base_config, domain_patterns, secrets):
        """Merge configuration sources with proper precedence"""
        return UnifiedConfig(
            # Environment-specific settings
            azure=AzureConfig(
                endpoints=base_config.azure_endpoints,
                credentials=secrets.azure_credentials,
                region=base_config.azure_region
            ),
            
            # Domain-specific patterns
            domain=DomainConfig(
                entity_types=domain_patterns.entity_types,
                relationship_patterns=domain_patterns.relationship_patterns,
                vector_weights=domain_patterns.vector_weights,
                gnn_model_config=domain_patterns.gnn_model_config
            ),
            
            # Observability settings
            observability=ObservabilityConfig(
                log_level=base_config.log_level,
                metrics_enabled=base_config.metrics_enabled,
                tracing_enabled=base_config.tracing_enabled
            )
        )
```

## ðŸš¨ **CURRENT STATUS & DIRECTION CHECKPOINT** (2025-07-31)

### **Implementation Progress Status**

| Phase | Components | Status | Progress |
|-------|------------|--------|----------|
| **Phase 1: Foundation** | Clean Architecture, DI, Azure Integration | âœ… **COMPLETE** | 27/27 tasks âœ… |
| **Phase 2 Week 3-4** | Agent Base + Discovery System | âœ… **COMPLETE** | 11/11 components âœ… |
| **âœ¨ Boundary Refactoring** | Layer boundaries, contracts, validation | âœ… **COMPLETE** | 7/7 tasks âœ… |
| **Phase 2 Week 5** | Tool Discovery Engine | ðŸŽ¯ **SHOULD BE CURRENT** | 0/4 tasks âŒ |

### **Recent Architecture Work Completed**
- âœ… **Layer Boundary Definitions**: Proper 5-layer hierarchy with enforcement
- âœ… **Service-Agent Boundary Corrections**: Interface contracts and delegation patterns
- âœ… **Core-Agent Infrastructure Integration**: Bounded memory with intelligence separation
- âœ… **Tri-Modal Orchestrator Placement**: Moved from `core/search/` to `agents/search/`
- âœ… **Contract Framework**: Runtime boundary enforcement with validation
- âœ… **Architecture Compliance**: 100% boundary validation success rate

### **ðŸ’¡ CRITICAL DIRECTION DECISION REQUIRED**

#### **Current Position**: Between Phase 2 Week 4 (Complete) â†” Week 5 (Tool Discovery)
**Key Question**: Should we continue with roadmap or complete remaining refactoring?

#### **Option 1: ðŸŽ¯ CONTINUE WITH ROADMAP (Recommended)**
**Next Focus**: Phase 2 Week 5 - Intelligent Tool Discovery
- âœ… **Pros**: Delivers user-facing features, maintains momentum, architecture is solid
- âš ï¸ **Cons**: Some refactoring incomplete (observability merge, reasoning engine cleanup)

#### **Option 2: ðŸ”„ COMPLETE REFACTORING**  
**Next Focus**: Finish all architecture cleanup
- âœ… **Pros**: Perfect architectural alignment
- âŒ **Cons**: Delays features, risk of over-engineering, lower user value

### **ðŸŽ¯ RECOMMENDATION: Continue with Roadmap**
**Rationale**: Foundation is solid (100% boundary validation), user value priority, manageable technical debt

### **Modified Components (Recent Boundary Work)**
- âœ… `agents/search/tri_modal_orchestrator.py` - Moved from core to proper agent layer
- âœ… `agents/base/integrated_memory_manager.py` - Proper Core-Agent integration  
- âœ… `contracts/inter_layer_contracts.py` - Complete inter-layer contract framework
- âœ… `docs/architecture/LAYER_BOUNDARY_DEFINITIONS.md` - High-level boundary specifications
- âœ… `tests/validation/simple_boundary_validation.py` - 100% boundary compliance validation

## Architecture Compliance Analysis

### **Critical Violations Identified** âš ï¸

#### 1. **Global State Anti-Pattern in Dependency Injection**
**Rule Violated**: Dependency Inversion and Testability
**Location**: `backend/api/dependencies.py:18-23`
- Uses global variables instead of proper DI container
- Makes testing difficult, creates hidden dependencies
- **Impact**: Breaks testability and SOLID principles

#### 2. **Direct Service Instantiation in Endpoints**
**Rule Violated**: Dependency Inversion and Testability
**Location**: `backend/api/endpoints/unified_search_endpoint.py:76`
- Direct `QueryService()` instantiation instead of DI
- **Code**: `query_service = QueryService()`
- **Impact**: Tight coupling, untestable components

#### 3. **Missing Async Patterns in Service Initialization**
**Rule Violated**: Async-First Performance Architecture
**Location**: Service initialization patterns
- Synchronous Azure service setup blocks startup
- **Impact**: Prevents parallel initialization, degrades performance

### **Moderate Violations** âš ï¸

#### 4. **Inconsistent Error Handling**
**Rule Violated**: Observable Enterprise Architecture
- Mixed logging levels and error context across services
- **Impact**: Difficult debugging, inconsistent observability

#### 5. **Configuration Scattered Across Files**
**Rule Violated**: Configuration-Driven Domain Agnostic Design
- Domain logic mixed with infrastructure config
- **Impact**: Harder to maintain domain universality

### **Architecture Health Score: 8.5/10** â¬†ï¸ (Improved from 6.5/10)

**Recent Improvements:**
- âœ… **Layer Boundaries Enforced**: 100% boundary compliance with runtime validation
- âœ… **Contract Framework Active**: Inter-layer interfaces properly defined and enforced
- âœ… **Core-Agent Integration**: Proper infrastructure/intelligence separation achieved
- âœ… **Tri-Modal Orchestrator**: Moved to correct architectural layer (agents)

**Current Strengths:**
- âœ… Clean layer separation with enforceable boundaries
- âœ… Proper Azure service abstraction layers
- âœ… Agent-centric architecture alignment achieved
- âœ… Comprehensive validation framework (100% success rate)
- âœ… Service-Agent delegation patterns implemented

**Remaining Issues (Non-Critical):**
- âš ï¸ Global state DI pattern (planned for Phase 3 cleanup)
- âš ï¸ Observability system integration pending
- âš ï¸ Duplicate reasoning engine component cleanup needed

### **Immediate Fix Priority**

#### **Week 1 - Critical Infrastructure**
1. **Replace Global DI with Proper Container**
   ```python
   # Replace dependencies.py with:
   from dependency_injector import containers, providers
   
   class ServiceContainer(containers.DeclarativeContainer):
       infrastructure = providers.Singleton(InfrastructureService)
       query_service = providers.Factory(QueryService, infrastructure=infrastructure)
   ```

2. **Implement Async Service Initialization**
   ```python
   async def initialize_services():
       """Parallel Azure service initialization"""
       await asyncio.gather(
           infrastructure.init_openai_client(),
           infrastructure.init_search_client(), 
           infrastructure.init_cosmos_client()
       )
   ```

#### **Week 2 - Service Layer Fixes**
3. **Fix Direct Service Instantiation**
   ```python
   # In all endpoints:
   async def endpoint(
       request: RequestModel,
       service: ServiceInterface = Depends(get_service)
   ):
   ```

4. **Standardize Azure Client Patterns**
   ```python
   @retry_with_backoff(max_attempts=3)
   async def execute_with_circuit_breaker(self, operation):
       """Standard Azure operation with resilience"""
   ```

#### **Week 3 - Observability & Configuration**
5. **Implement Structured Logging**
   ```python
   logger.info("operation_completed", 
              operation="unified_search", 
              duration=time, success=True, 
              sources_found=count)
   ```

6. **Centralize Configuration Management**
   ```python
   @dataclass 
   class UnifiedConfig:
       azure: AzureConfig
       domain: DomainConfig
       observability: ObservabilityConfig
   ```

### **Compliance Monitoring**
- All new code must pass architectural design rule checks
- No direct service instantiation allowed
- All I/O operations must be async
- Structured logging required for all operations
- Configuration-driven behavior enforced

## API Layer Consolidation Analysis

### **Critical Issues Found in Current API Layer** âš ï¸

#### **1. Severe Endpoint Overlap**
**Problem**: Multiple endpoints doing the same core query functionality:

| File | Purpose | Request Model | Issues |
|------|---------|---------------|---------|
| `query_endpoint.py` | Azure query processing | `AzureQueryRequest` | âœ… Uses proper DI |
| `unified_search_endpoint.py` | Demo tri-modal search | `UnifiedSearchRequest` | âŒ Direct service instantiation |
| `gnn_endpoint.py` | GNN enhanced queries | `GNNQueryRequest` | âŒ Global state, no DI |

**Impact**: API consumers confused by 3 different query interfaces for same functionality.

#### **2. Demo Endpoint Fragmentation**
**Problem**: 4 separate demo approaches instead of unified demo API:

```
/api/v1/demo/supervisor-overview     (demo_endpoint.py)
/api/v1/demo/graph-stats            (graph_endpoint.py)  
/api/v1/gremlin/query               (gremlin_endpoint.py)
/api/v1/unified-search/demo         (unified_search_endpoint.py)
```

**Impact**: Inconsistent demo experience, multiple APIs to maintain.

#### **3. Architecture Violations**
```python
# âŒ VIOLATIONS FOUND:

# Direct service instantiation (Rule 6 violation)
workflow_service = WorkflowService()  # workflow_endpoint.py:11
query_service = QueryService()       # unified_search_endpoint.py:76

# Global state anti-pattern (Rule 6 violation)  
gnn_service = None                   # gnn_endpoint.py:19

# Mixed dependency patterns (inconsistent)
from api.dependencies import get_query_service     # Good
from services.query_service import QueryService    # Bad - bypasses DI
```

### **Recommended API Layer Consolidation** âœ…

#### **Phase 1: Unified Query API**
**Replace 3 query endpoints with 1 comprehensive endpoint:**

```python
# api/endpoints/unified_query_endpoint.py
@router.post("/api/v1/query")
async def universal_query(
    request: UniversalQueryRequest,
    query_service: QueryService = Depends(get_query_service)
) -> UniversalQueryResponse:
    """
    Single unified query endpoint supporting:
    - Vector search (cognitive search)
    - Graph traversal (knowledge graphs)  
    - GNN enhancement (neural predictions)
    - All query types and domains
    """
    return await query_service.process_universal_query(
        query=request.query,
        domain=request.domain,
        search_types=request.search_types,  # ["vector", "graph", "gnn"]
        max_results=request.max_results,
        include_demo_details=request.demo_mode
    )

# Unified request model
class UniversalQueryRequest(BaseModel):
    query: str = Field(..., description="Query to process")
    domain: str = Field(default="general", description="Domain context")
    search_types: List[str] = Field(default=["vector", "graph", "gnn"], description="Search modalities")
    max_results: int = Field(default=20, description="Results per modality")
    demo_mode: bool = Field(default=False, description="Include demo breakdown")
```

#### **Phase 2: Unified Demo API**
**Replace 4 demo endpoints with 1 comprehensive demo API:**

```python
# api/endpoints/demo_endpoint.py  
@router.get("/api/v1/demo/{demo_type}")
async def get_demo_data(
    demo_type: DemoType,
    query_service: QueryService = Depends(get_query_service),
    graph_service: GraphService = Depends(get_graph_service)
) -> DemoResponse:
    """
    Single demo endpoint supporting:
    - system_overview: High-level system stats
    - tri_modal_search: Live tri-modal search demo
    - knowledge_graph: Graph traversal demo
    - performance_metrics: System performance data
    """

class DemoType(str, Enum):
    SYSTEM_OVERVIEW = "system-overview"
    TRI_MODAL_SEARCH = "tri-modal-search"  
    KNOWLEDGE_GRAPH = "knowledge-graph"
    PERFORMANCE_METRICS = "performance"
```

#### **Phase 3: Clean Architecture Enforcement**
**Fix all architectural violations:**

```python
# âœ… CORRECT PATTERNS:

# 1. Proper dependency injection everywhere
async def endpoint(
    request: RequestModel,
    service: ServiceInterface = Depends(get_service)  # Always use DI
):

# 2. No global service instances
# Remove all: service = SomeService()

# 3. Consistent service access
# Always: from api.dependencies import get_service
# Never: from services.service import Service

# 4. Interface-based service layer
class QueryServiceInterface(ABC):
    @abstractmethod
    async def process_universal_query(...) -> Result: ...
```

### **Consolidation Benefits**

#### **For API Consumers**
- âœ… **Single query endpoint** instead of 3 confusing options
- âœ… **Unified demo API** with consistent interface
- âœ… **Clear capabilities** per endpoint without overlap

#### **For Development Team**  
- âœ… **Reduced maintenance** - 2 endpoints instead of 7
- âœ… **Consistent patterns** - All endpoints follow same DI approach
- âœ… **Architecture compliance** - No violations, clean boundaries

#### **For System Architecture**
- âœ… **Clean API surface** aligned with tri-modal principles
- âœ… **Proper layer separation** with consistent DI patterns
- âœ… **Unified functionality** instead of fragmented capabilities

### **Implementation Priority**

#### **Critical (Week 1)**
1. **Consolidate query endpoints** - Replace 3 with 1 unified endpoint
2. **Fix DI violations** - Remove direct service instantiation
3. **Remove global state** - Eliminate global service variables

#### **High (Week 2)** 
4. **Consolidate demo endpoints** - Replace 4 with 1 unified demo API
5. **Standardize service access** - Consistent dependency injection patterns

#### **Medium (Week 3)**
6. **Remove redundant files** - Clean up old endpoint files
7. **Update API documentation** - Reflect consolidated endpoints

## Strategic Priorities

### Immediate Focus
1. **Agent Intelligence Integration**: Implement data-driven agent reasoning with dynamic tool discovery
2. **Performance Optimization**: Enhance parallel processing pipeline including agent orchestration
3. **GNN Integration**: Advance real-time neural network inference for agent predictive intelligence
4. **Enterprise Features**: Strengthen monitoring and compliance for agent workflows
5. **Universal Domain Discovery**: Replace hardcoded patterns with dynamic learning from raw text

### Long-term Vision
- **Revolutionary RAG Intelligence**: First system combining tri-modal search with data-driven intelligent agents
- **Universal Knowledge Adaptation**: Zero-configuration deployment for any domain from raw text data
- **Predictive Problem Solving**: Agents solve problems not explicitly in training data using GNN predictions
- **Dynamic Tool Ecosystems**: Self-evolving agent capabilities that improve from domain interactions
- **Enterprise-Grade Intelligence**: Production-ready agent workflows with full observability and reliability

---

*This document is a living record of our project architecture and will be updated throughout development to reflect our evolving understanding and improvements.*