#!/usr/bin/env python3
"""
Demo Real GNN Training - Production-Ready Code
Demonstrates the actual training code that would run on Azure ML
"""

import json
import numpy as np
import sys
import argparse
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, Tuple
import logging
import torch
import torch.nn.functional as F
from torch_geometric.nn import GATConv, global_mean_pool, BatchNorm
from torch_geometric.data import Data
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, f1_score

sys.path.append(str(Path(__file__).parent.parent))

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RealGraphAttentionNet(torch.nn.Module):
    """Real Graph Attention Network - Production Implementation"""
    
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=3, heads=8, dropout=0.2):
        super(RealGraphAttentionNet, self).__init__()
        
        self.num_layers = num_layers
        self.dropout = dropout
        
        # GAT layers with batch normalization
        self.gat_layers = torch.nn.ModuleList()
        self.batch_norms = torch.nn.ModuleList()
        
        # Input layer
        self.gat_layers.append(
            GATConv(input_dim, hidden_dim, heads=heads, dropout=dropout, concat=True)
        )
        self.batch_norms.append(BatchNorm(hidden_dim * heads))
        
        # Hidden layers
        for i in range(num_layers - 2):
            self.gat_layers.append(
                GATConv(hidden_dim * heads, hidden_dim, heads=heads, dropout=dropout, concat=True)
            )
            self.batch_norms.append(BatchNorm(hidden_dim * heads))
        
        # Output layer
        self.gat_layers.append(
            GATConv(hidden_dim * heads, output_dim, heads=1, dropout=dropout, concat=False)
        )
        
        # Residual connections
        self.residual_layers = torch.nn.ModuleList()
        for i in range(num_layers - 1):
            if i == 0:
                self.residual_layers.append(torch.nn.Linear(input_dim, hidden_dim * heads))
            else:
                self.residual_layers.append(torch.nn.Linear(hidden_dim * heads, hidden_dim * heads))
        
    def forward(self, x, edge_index, batch=None):
        # Store input for residual connections
        residual = x
        
        # Apply GAT layers with residual connections
        for i, (gat_layer, batch_norm) in enumerate(zip(self.gat_layers[:-1], self.batch_norms)):
            x = gat_layer(x, edge_index)
            
            # Batch normalization
            x = batch_norm(x)
            
            # Residual connection
            if i < len(self.residual_layers):
                residual = self.residual_layers[i](residual)
                x = x + residual
                residual = x
            
            # Activation and dropout
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout, training=self.training)
        
        # Output layer
        x = self.gat_layers[-1](x, edge_index)
        
        return F.log_softmax(x, dim=1)

def load_training_data(data_path):
    """Load context-aware training data"""
    
    logger.info(f"Loading training data from: {data_path}")
    
    # Load numpy data
    data = np.load(data_path)
    
    node_features = torch.FloatTensor(data['node_features'])
    edge_index = torch.LongTensor(data['edge_index'])
    node_labels = torch.LongTensor(data['node_labels'])
    
    logger.info(f"Real training data loaded:")
    logger.info(f"  ‚Ä¢ Nodes: {node_features.shape[0]}")
    logger.info(f"  ‚Ä¢ Features: {node_features.shape[1]}")
    logger.info(f"  ‚Ä¢ Edges: {edge_index.shape[1]}")
    logger.info(f"  ‚Ä¢ Classes: {len(torch.unique(node_labels))}")
    
    return node_features, edge_index, node_labels

def create_data_splits(node_features, node_labels, test_size=0.2, val_size=0.1):
    """Create stratified train/val/test splits"""
    
    num_nodes = node_features.shape[0]
    indices = np.arange(num_nodes)
    
    # Ensure we have enough samples per class
    unique_labels, counts = np.unique(node_labels, return_counts=True)
    min_samples = min(counts)
    
    if min_samples < 3:
        logger.warning(f"Some classes have very few samples (min: {min_samples})")
    
    # Train/test split
    train_idx, test_idx = train_test_split(
        indices, test_size=test_size, random_state=42, 
        stratify=node_labels if min_samples >= 2 else None
    )
    
    # Train/val split
    if len(train_idx) > 10:  # Only create val set if we have enough data
        train_idx, val_idx = train_test_split(
            train_idx, test_size=val_size/(1-test_size), random_state=42,
            stratify=node_labels[train_idx] if min_samples >= 3 else None
        )
    else:
        val_idx = train_idx[:len(train_idx)//2]
        train_idx = train_idx[len(train_idx)//2:]
    
    logger.info(f"Data splits:")
    logger.info(f"  ‚Ä¢ Training: {len(train_idx)} nodes")
    logger.info(f"  ‚Ä¢ Validation: {len(val_idx)} nodes")
    logger.info(f"  ‚Ä¢ Test: {len(test_idx)} nodes")
    
    return train_idx, val_idx, test_idx

def train_real_model(model, data, train_idx, val_idx, optimizer, scheduler, device, epochs=200):
    """Real model training - Production Implementation"""
    
    node_features, edge_index, node_labels = data
    
    best_val_acc = 0
    patience = 20
    patience_counter = 0
    
    logger.info("üöÄ Starting REAL GNN training...")
    logger.info("üéØ This is the ACTUAL training code that runs on Azure ML!")
    
    # Create outputs directory
    outputs_dir = Path("outputs")
    outputs_dir.mkdir(exist_ok=True)
    
    for epoch in range(epochs):
        # Training phase
        model.train()
        optimizer.zero_grad()
        
        # Forward pass
        out = model(node_features, edge_index)
        
        # Compute loss on training nodes
        loss = F.nll_loss(out[train_idx], node_labels[train_idx])
        
        # Backward pass
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping
        optimizer.step()
        
        # Validation phase
        if epoch % 5 == 0:
            model.eval()
            with torch.no_grad():
                val_out = model(node_features, edge_index)
                val_pred = val_out[val_idx].argmax(dim=1)
                val_acc = accuracy_score(node_labels[val_idx].cpu(), val_pred.cpu())
                val_f1 = f1_score(node_labels[val_idx].cpu(), val_pred.cpu(), average='weighted')
            
            logger.info(f"Epoch {epoch:3d}: Loss={loss:.4f}, Val Acc={val_acc:.4f}, Val F1={val_f1:.4f}")
            
            # Early stopping and model saving
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                patience_counter = 0
                
                # Save best model
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'best_val_acc': best_val_acc,
                    'val_f1_score': val_f1
                }, "outputs/best_gnn_model.pt")
                
                logger.info(f"‚úÖ New best model saved! Val Acc: {best_val_acc:.4f}")
            else:
                patience_counter += 1
            
            # Early stopping
            if patience_counter >= patience:
                logger.info(f"Early stopping at epoch {epoch} (patience={patience})")
                break
            
            model.train()
        
        # Learning rate scheduling
        scheduler.step()
    
    return best_val_acc

def evaluate_real_model(model, data, test_idx):
    """Real model evaluation with comprehensive metrics"""
    
    node_features, edge_index, node_labels = data
    
    # Load best model
    checkpoint = torch.load("outputs/best_gnn_model.pt")
    model.load_state_dict(checkpoint['model_state_dict'])
    
    model.eval()
    with torch.no_grad():
        out = model(node_features, edge_index)
        test_pred = out[test_idx].argmax(dim=1)
        
        test_acc = accuracy_score(node_labels[test_idx].cpu(), test_pred.cpu())
        test_f1 = f1_score(node_labels[test_idx].cpu(), test_pred.cpu(), average='weighted')
        
        # Detailed classification report
        report = classification_report(
            node_labels[test_idx].cpu(), 
            test_pred.cpu(), 
            output_dict=True,
            zero_division=0
        )
    
    logger.info(f"üèÜ Final test results:")
    logger.info(f"  ‚Ä¢ Test Accuracy: {test_acc:.4f}")
    logger.info(f"  ‚Ä¢ Test F1 Score: {test_f1:.4f}")
    
    return test_acc, test_f1, report

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--partial", action="store_true", help="Use partial dataset")
    parser.add_argument("--hidden_dim", type=int, default=256)
    parser.add_argument("--num_layers", type=int, default=3)
    parser.add_argument("--heads", type=int, default=8)
    parser.add_argument("--dropout", type=float, default=0.2)
    parser.add_argument("--learning_rate", type=float, default=0.001)
    parser.add_argument("--epochs", type=int, default=100)  # Reduced for demo
    parser.add_argument("--weight_decay", type=float, default=1e-4)
    
    args = parser.parse_args()
    
    print("üî• DEMO: REAL GNN TRAINING CODE")
    print("=" * 50)
    print("üéØ This demonstrates the ACTUAL training code")
    print("üì¶ Same code that would run on Azure ML")
    print("üöÄ Production-ready PyTorch Geometric implementation")
    print("=" * 50)
    
    # Setup device - use GPU if available
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"Using device: {device}")
    
    if torch.cuda.is_available():
        logger.info(f"GPU: {torch.cuda.get_device_name(0)}")
        logger.info(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    else:
        logger.info("Using CPU (GPU would be available on Azure ML)")
    
    # Find training data
    data_dir = Path(__file__).parent.parent / "data" / "gnn_training"
    data_pattern = "gnn_training_data_partial_*.npz" if args.partial else "gnn_training_data_full_*.npz"
    data_files = list(data_dir.glob(data_pattern))
    
    if not data_files:
        logger.error(f"No training data found. Run prepare_gnn_training_features.py first")
        return
    
    latest_data_file = max(data_files, key=lambda x: x.stat().st_mtime)
    logger.info(f"üìÑ Using training data: {latest_data_file}")
    
    # Load context-aware training data
    node_features, edge_index, node_labels = load_training_data(latest_data_file)
    
    # Move to device
    node_features = node_features.to(device)
    edge_index = edge_index.to(device)
    node_labels = node_labels.to(device)
    
    # Create splits
    train_idx, val_idx, test_idx = create_data_splits(node_features.cpu(), node_labels.cpu())
    train_idx = torch.LongTensor(train_idx).to(device)
    val_idx = torch.LongTensor(val_idx).to(device)
    test_idx = torch.LongTensor(test_idx).to(device)
    
    # Create real model
    input_dim = node_features.shape[1]
    output_dim = len(torch.unique(node_labels))
    
    model = RealGraphAttentionNet(
        input_dim=input_dim,
        hidden_dim=args.hidden_dim,
        output_dim=output_dim,
        num_layers=args.num_layers,
        heads=args.heads,
        dropout=args.dropout
    ).to(device)
    
    logger.info(f"üß† Real GNN model created:")
    logger.info(f"  ‚Ä¢ Input dim: {input_dim}")
    logger.info(f"  ‚Ä¢ Hidden dim: {args.hidden_dim}")
    logger.info(f"  ‚Ä¢ Output classes: {output_dim}")
    logger.info(f"  ‚Ä¢ Parameters: {sum(p.numel() for p in model.parameters()):,}")
    
    # Optimizer and scheduler
    optimizer = torch.optim.AdamW(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs, eta_min=1e-6)
    
    # Train real model
    data = (node_features, edge_index, node_labels)
    best_val_acc = train_real_model(model, data, train_idx, val_idx, optimizer, scheduler, device, args.epochs)
    
    # Evaluate real model
    test_acc, test_f1, report = evaluate_real_model(model, data, test_idx)
    
    # Save comprehensive results
    results = {
        "model_info": {
            "model_type": "RealGraphAttentionNetwork",
            "input_dim": input_dim,
            "hidden_dim": args.hidden_dim,
            "output_dim": output_dim,
            "num_parameters": sum(p.numel() for p in model.parameters()),
            "device": str(device),
            "training_mode": "demo_real_training"
        },
        "training_results": {
            "best_val_accuracy": float(best_val_acc),
            "final_test_accuracy": float(test_acc),
            "final_test_f1": float(test_f1),
            "epochs_trained": args.epochs
        },
        "data_info": {
            "total_nodes": int(node_features.shape[0]),
            "feature_dimension": int(node_features.shape[1]),
            "num_edges": int(edge_index.shape[1]),
            "num_classes": int(output_dim),
            "train_nodes": int(len(train_idx)),
            "val_nodes": int(len(val_idx)),
            "test_nodes": int(len(test_idx)),
            "data_file": str(latest_data_file)
        },
        "classification_report": report
    }
    
    with open("outputs/demo_real_training_results.json", "w") as f:
        json.dump(results, f, indent=2)
    
    print("\nüéâ DEMO: REAL GNN TRAINING COMPLETED!")
    print("=" * 50)
    print(f"üèÜ Best validation accuracy: {best_val_acc:.4f}")
    print(f"üéØ Final test accuracy: {test_acc:.4f}")
    print(f"üìä F1 Score: {test_f1:.4f}")
    print(f"üß† Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    print("\nüí° This exact code runs on Azure ML with:")
    print("   ‚úÖ Real GPU compute clusters")
    print("   ‚úÖ MLflow experiment tracking")
    print("   ‚úÖ Azure ML model registry")
    print("   ‚úÖ Production deployment endpoints")
    print("\nüîó To run on Azure ML:")
    print("   1. Set Azure credentials")
    print("   2. python scripts/setup_azure_ml_real.py")
    print("   3. python scripts/real_azure_ml_gnn_training.py --partial --wait")

if __name__ == "__main__":
    main()