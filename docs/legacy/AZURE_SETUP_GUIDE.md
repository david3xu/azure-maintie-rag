# ğŸš€ Azure Universal RAG - Minimal Setup Guide

## âœ… **Your Architecture is Already Ready!**

Your `make dev` is already architected for Azure services integration. Based on your existing codebase analysis, here are the **minimal setup instructions**:

## ğŸ”§ **Setup Options: Manual vs Automated**

### **Option 1: Automated Configuration** ğŸš€ **RECOMMENDED**
**Single command deployment with automatic configuration:**

```bash
# Deploy Azure infrastructure + auto-configure + start development
make azure-dev-auto
```

**Benefits:**
- âœ… **No manual .env copying**
- âœ… **No manual key configuration**
- âœ… **No manual endpoint configuration**
- âœ… **Uses Azure Key Vault/Managed Identity**
- âœ… **Data-driven from Bicep templates**

### **Option 2: Manual Configuration** (Your current approach)
**Step 1: Environment Configuration** âœ… COMPLETED
```bash
# âœ… Already done: Environment file created
cp backend/config/environment_example.env backend/.env
```

**Step 2: Azure Service Endpoints Configuration**
**Update `backend/.env` with values from your deployment output:**

```bash
# Run the automated update script
./scripts/update-env-from-deployment.sh
```

**Or manually update these values in `backend/.env`:**
```bash
# From your ./scripts/enhanced-complete-redeploy.sh output:
AZURE_STORAGE_ACCOUNT=maintiedevmlstor1cdd8e11
AZURE_SEARCH_SERVICE=maintie-dev-search-1cdd8e
AZURE_COSMOS_ENDPOINT=https://maintie-dev-cosmos-1cdd8e11.documents.azure.com:443/
AZURE_KEY_VAULT_URL=https://maintie-dev-kv-[token].vault.azure.net/

# Azure OpenAI (your existing configuration)
OPENAI_API_BASE=https://your-azure-openai-instance.openai.azure.com/
OPENAI_API_KEY=your-azure-openai-key
```

### **Step 3: API Keys Configuration** âš ï¸ REQUIRED
**Get these from Azure Portal and update `backend/.env`:**
- `AZURE_STORAGE_KEY` - Storage account access key
- `AZURE_SEARCH_KEY` - Search service admin key
- `AZURE_COSMOS_KEY` - Cosmos DB primary key
- `OPENAI_API_KEY` - Your Azure OpenAI API key

## ğŸš€ **Start Development** (Your existing commands)
```bash
# Your existing workflow works:
make dev

# Services will be available at:
# Backend API: http://localhost:8000 (with Azure services)
# Frontend UI: http://localhost:5174 (connects to backend)
```

## ğŸ” **Verification Commands** (Your existing targets)
```bash
# Verify setup works
make health

# Check Azure services connectivity
curl http://localhost:8000/api/v1/health
curl http://localhost:8000/health/detailed

# Test workflow integration
make test-workflow
```

## ğŸ“‹ **Configuration Checklist**

**Required environment variables in `backend/.env`:**
- âœ… `AZURE_STORAGE_ACCOUNT` and `AZURE_STORAGE_KEY`
- âœ… `AZURE_SEARCH_SERVICE` and `AZURE_SEARCH_KEY`
- âœ… `AZURE_COSMOS_ENDPOINT` and `AZURE_COSMOS_KEY`
- âœ… `OPENAI_API_BASE` and `OPENAI_API_KEY`
- âœ… `AZURE_KEY_VAULT_URL` (optional for enhanced security)

## ğŸ¯ **What's Already Working**

### **Your Existing Architecture:**
1. **âœ… Azure Services Manager** - Already initialized in `main.py`
2. **âœ… Configuration Validation** - Added startup validation
3. **âœ… Environment Settings** - Complete Azure settings support
4. **âœ… Service Integration** - All Azure services integrated
5. **âœ… Development Workflow** - `make dev` ready for Azure

### **Your Existing Features:**
- **âœ… Three-layer progressive disclosure** - Workflow transparency
- **âœ… Real-time streaming queries** - Azure-powered backend
- **âœ… Universal RAG processing** - Domain-agnostic text processing
- **âœ… Azure Cognitive Search** - Vector search integration
- **âœ… Azure OpenAI processing** - LLM integration
- **âœ… Azure Blob Storage (Multi-Account)** - RAG data, ML models, and app data storage
- **âœ… Azure Cosmos DB** - Metadata storage

## ğŸ”§ **Optional Enhancement: Startup Validation** âœ… ADDED

**Added to `backend/api/main.py` lifespan function:**
```python
# ADD: Validation check
validation_result = azure_settings.validate_azure_config()
logger.info(f"Azure configuration validation: {validation_result}")

# Log validation details
for service, configured in validation_result.items():
    status = "âœ…" if configured else "âŒ"
    logger.info(f"  {status} {service}: {'Configured' if configured else 'Not configured'}")
```

## ğŸš€ **Quick Start Commands**

### **Automated Approach (Recommended)**
```bash
# Single command: Deploy + Configure + Start Development
make azure-dev-auto
```

### **Manual Approach**
```bash
# 1. Update environment with Azure endpoints
./scripts/update-env-from-deployment.sh

# 2. Update API keys in backend/.env (manual step)

# 3. Start development
make dev

# 4. Verify everything works
make health
```

## ğŸ” **Security Benefits**

### **Automated Approach**
- âœ… **Azure Key Vault**: Secrets stored securely in Azure
- âœ… **Managed Identity**: No keys in source code or files
- âœ… **Credential Chain**: Automatic authentication resolution
- âœ… **Enterprise Security**: Follows Azure security best practices

### **Manual Approach**
- âŒ **Manual Key Management**: Keys in plain text files
- âŒ **Security Risk**: Potential key exposure
- âŒ **Operational Overhead**: Manual configuration required

## ğŸ“Š **Expected Output**

When you run `make dev`, you should see:
```
ğŸš€ Starting Universal RAG system:

ğŸ“ Backend API:   http://localhost:8000 (Universal RAG service)
ğŸ“ Frontend UI:   http://localhost:5174 (Workflow transparency)
ğŸ“ API Docs:      http://localhost:8000/docs
ğŸ“ Workflow API:  http://localhost:8000/api/v1/query/stream/{query_id}

ğŸ”„ Features: Three-layer progressive disclosure + real-time workflow tracking
```

## ğŸ‰ **Result**

After setup, your `make dev` will:
1. **Start backend** with Azure services initialization
2. **Start frontend** connecting to Azure-powered backend
3. **Enable real-time workflow** with three-layer progressive disclosure
4. **Provide Azure service integration** through your existing architecture

**Your existing architecture requires minimal changes** - primarily environment configuration with deployed Azure service endpoints.

## ğŸ” **Troubleshooting**

### **If services don't start:**
```bash
# Check Azure CLI authentication
az login

# Verify resource group exists
az group show --name maintie-rag-rg

# Check service status
./scripts/status-working.sh
```

### **If configuration validation fails:**
```bash
# Check .env file
cat backend/.env

# Re-run environment update
./scripts/update-env-from-deployment.sh
```

### **If API keys are missing:**
1. Go to Azure Portal
2. Navigate to each service (Storage, Search, Cosmos DB)
3. Copy the access keys
4. Update `backend/.env`

## ğŸ“ **Summary**

**Your architecture is already perfect for Azure integration!** You now have **two approaches**:

### **Automated Approach (Recommended)**
```bash
make azure-dev-auto  # Deploy + Configure + Start Development
```

### **Manual Approach**
1. âœ… **Environment file created** (`backend/.env`)
2. âœ… **Startup validation added** (in `main.py`)
3. âš ï¸ **Update service endpoints** (run `./scripts/update-env-from-deployment.sh`)
4. âš ï¸ **Add API keys** (manual step from Azure Portal)

**The automated approach eliminates manual configuration and uses Azure security best practices!**