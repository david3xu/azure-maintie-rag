Based on the existing codebase analysis, I'll provide an enterprise architecture solution for the Azure Universal RAG deployment orchestration.## **Enterprise Deployment Architecture Recommendation**

Based on the existing codebase analysis, the optimal approach is a **Service-Specific Deployment with Master Orchestrator** pattern. This aligns with Azure enterprise architecture principles and your data-driven configuration requirements.

### **Current Codebase Analysis**

From the existing code, you have:
- **3 Bicep Templates**: Core, ML, Cosmos DB
- **Environment Configurations**: `backend/config/environments/*.env`
- **Single Orchestrator**: `scripts/enhanced-complete-redeploy.sh` (experiencing dependency issues)

### **Recommended Architecture Pattern**

**Create 4 Scripts Total**:

1. **`scripts/deploy-core.sh`** - Core infrastructure deployment
2. **`scripts/deploy-ml.sh`** - ML workspace deployment
3. **`scripts/deploy-cosmos.sh`** - Cosmos DB deployment
4. **`scripts/azure-deployment-orchestrator.sh`** - Master orchestrator (updated)

### **Service-Specific Script Implementation**

#### **Script 1: `scripts/deploy-core.sh`**

**Purpose:** Deploy core infrastructure and store outputs for downstream services

**Key Features:**
- Deploy `azure-resources-core.bicep`
- Store deployment outputs in `.deployment_core_outputs.json`
- Environment-driven configuration from `backend/config/environments/*.env`

#### **Script 2: `scripts/deploy-ml.sh`**

**Purpose:** Deploy ML infrastructure with core dependencies

**Key Features:**
- Read core outputs from `.deployment_core_outputs.json`
- Deploy `azure-resources-ml-simple.bicep`
- Pass actual resource references from core deployment

#### **Script 3: `scripts/deploy-cosmos.sh`**

**Purpose:** Deploy Cosmos DB with proper configuration

**Key Features:**
- Deploy `azure-resources-cosmos.bicep`
- Environment-specific throughput from configuration files
- Store connection details for application configuration

#### **Script 4: `scripts/azure-deployment-orchestrator.sh`** (Master)

**Purpose:** Service orchestration with dependency management

**Key Features:**
- Sequential deployment: Core â†’ ML â†’ Cosmos
- Dependency validation between services
- Rollback capabilities
- Health checks and verification

### **Enterprise Benefits of This Pattern**

#### **1. Service Boundary Separation**
- Each Azure service has independent deployment lifecycle
- Enables selective service updates without full redeployment
- Supports different update frequencies per service tier

#### **2. Dependency Management**
- Clear dependency chain: Core â†’ ML â†’ Cosmos
- Output/input contract between services
- Prevents circular dependencies

#### **3. Enterprise Scalability**
- Supports Azure DevOps pipeline integration
- Enables GitOps deployment patterns
- Facilitates multi-environment promotion (dev â†’ staging â†’ prod)

#### **4. Operational Excellence**
- Granular error handling per service
- Service-specific retry logic
- Independent service health monitoring

### **Data-Driven Configuration Integration**

**From Existing Codebase Patterns:**

1. **Environment Configuration Loading**
   ```bash
   # Each script loads from backend/config/environments/${ENVIRONMENT}.env
   source "backend/config/environments/${ENVIRONMENT}.env"
   ```

2. **Resource Naming from Configuration**
   ```bash
   # Use existing resourcePrefix and environment variables
   RESOURCE_PREFIX="${AZURE_RESOURCE_PREFIX}"
   ENVIRONMENT="${AZURE_ENVIRONMENT}"
   ```

3. **Service Configuration from Templates**
   ```bash
   # Pass environment-specific parameters to Bicep
   --parameters "environment=${ENVIRONMENT}" "resourcePrefix=${RESOURCE_PREFIX}"
   ```

### **Implementation Priority**

**Based on your current deployment issues:**

1. **Immediate:** Fix core deployment output capture in `deploy-core.sh`
2. **Next:** Create `deploy-ml.sh` with proper dependency resolution
3. **Then:** Create `deploy-cosmos.sh` with corrected template parameters
4. **Finally:** Update master orchestrator for service coordination

### **Azure Enterprise Integration Points**

#### **Azure DevOps Integration**
- Each service script becomes a pipeline stage
- Template validation in PR builds
- Environment-specific variable groups

#### **Azure Resource Manager Integration**
- Template specs for versioned deployments
- Resource group organization by service boundary
- RBAC assignment per service tier

#### **Azure Monitor Integration**
- Service-specific Application Insights instances
- Deployment success/failure metrics
- Cross-service dependency monitoring

This architecture maintains your data-driven approach while providing enterprise-grade deployment orchestration and service lifecycle management.



## **Azure Universal RAG - Enterprise Service Deployment Architecture**

Based on your existing codebase patterns, here are the **precise code instructions** for implementing the service-specific deployment architecture:

### **Service 1: Core Infrastructure Deployment**

**Create:** `scripts/deploy-core.sh`

```bash
#!/bin/bash
# Azure Universal RAG - Core Infrastructure Service
# Deploys: Storage, Search, KeyVault, AppInsights, LogAnalytics

set -euo pipefail

# Load environment configuration from existing pattern
ENVIRONMENT="${AZURE_ENVIRONMENT:-dev}"
RESOURCE_GROUP="${AZURE_RESOURCE_GROUP:-maintie-rag-rg}"
AZURE_LOCATION="${AZURE_LOCATION:-eastus}"

# Source environment-specific configuration
if [ -f "backend/config/environments/${ENVIRONMENT}.env" ]; then
    source "backend/config/environments/${ENVIRONMENT}.env"
fi

# Color coding from existing codebase
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

print_info() { echo -e "${BLUE}â„¹ï¸  $1${NC}"; }
print_status() { echo -e "${GREEN}âœ… $1${NC}"; }
print_warning() { echo -e "${YELLOW}âš ï¸  $1${NC}"; }
print_error() { echo -e "${RED}âŒ $1${NC}"; }

deploy_core_service() {
    print_info "ðŸ—ï¸  Azure Core Infrastructure Service Deployment"

    # Generate deterministic deployment token using existing pattern
    local deployment_token=$(echo -n "${RESOURCE_GROUP}-${ENVIRONMENT}-${AZURE_RESOURCE_PREFIX}" | sha256sum | cut -c1-8)

    # Deploy core infrastructure
    local deployment_output
    if deployment_output=$(az deployment group create \
        --resource-group "${RESOURCE_GROUP}" \
        --template-file "infrastructure/azure-resources-core.bicep" \
        --parameters "environment=${ENVIRONMENT}" \
                    "location=${AZURE_LOCATION}" \
                    "resourcePrefix=${AZURE_RESOURCE_PREFIX}" \
                    "deploymentToken=${deployment_token}" \
        --name "core-service-$(date +%Y%m%d-%H%M%S)" \
        --mode Incremental \
        --output json); then

        # Store deployment outputs for downstream services
        echo "${deployment_output}" > ".deployment_core_outputs.json"
        echo "${deployment_token}" > ".deployment_token"

        # Extract service endpoints for configuration
        local storage_name=$(echo "${deployment_output}" | jq -r '.properties.outputs.storageAccountName.value')
        local search_name=$(echo "${deployment_output}" | jq -r '.properties.outputs.searchServiceName.value')
        local keyvault_name=$(echo "${deployment_output}" | jq -r '.properties.outputs.keyVaultName.value')

        # Store for service integration
        echo "${storage_name}" > ".deployment_storage_name"
        echo "${search_name}" > ".deployment_search_name"
        echo "${keyvault_name}" > ".deployment_keyvault_name"

        print_status "Core infrastructure service deployed successfully"
        print_info "Service Endpoints:"
        print_info "  - Storage: ${storage_name}"
        print_info "  - Search: ${search_name}"
        print_info "  - KeyVault: ${keyvault_name}"

        return 0
    else
        print_error "Core infrastructure service deployment failed"
        return 1
    fi
}

# Service health validation
validate_core_service() {
    print_info "ðŸ” Validating Core Service Health..."

    local validation_failed=false

    # Validate each core service using existing patterns
    local required_services=("Microsoft.Storage/storageAccounts" "Microsoft.Search/searchServices" "Microsoft.KeyVault/vaults")

    for service_type in "${required_services[@]}"; do
        local service_count=$(az resource list \
            --resource-group "${RESOURCE_GROUP}" \
            --resource-type "${service_type}" \
            --query "length(@)" \
            --output tsv 2>/dev/null || echo "0")

        if [ "${service_count}" -eq 0 ]; then
            print_error "Core service validation failed: ${service_type}"
            validation_failed=true
        else
            print_status "Core service validated: ${service_type}"
        fi
    done

    if [ "${validation_failed}" = true ]; then
        return 1
    fi

    print_status "Core service health validation passed"
    return 0
}

main() {
    if ! deploy_core_service; then
        exit 1
    fi

    if ! validate_core_service; then
        exit 1
    fi

    print_status "ðŸŽ‰ Core Infrastructure Service Ready"
}

main "$@"
```

### **Service 2: ML Workspace Deployment**

**Create:** `scripts/deploy-ml.sh`

```bash
#!/bin/bash
# Azure Universal RAG - ML Workspace Service
# Deploys: ML Storage, ML Workspace with Core Dependencies

set -euo pipefail

# Load configuration from existing patterns
ENVIRONMENT="${AZURE_ENVIRONMENT:-dev}"
RESOURCE_GROUP="${AZURE_RESOURCE_GROUP:-maintie-rag-rg}"
AZURE_LOCATION="${AZURE_LOCATION:-eastus}"

# Source environment configuration
if [ -f "backend/config/environments/${ENVIRONMENT}.env" ]; then
    source "backend/config/environments/${ENVIRONMENT}.env"
fi

# Color coding from existing codebase
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

print_info() { echo -e "${BLUE}â„¹ï¸  $1${NC}"; }
print_status() { echo -e "${GREEN}âœ… $1${NC}"; }
print_warning() { echo -e "${YELLOW}âš ï¸  $1${NC}"; }
print_error() { echo -e "${RED}âŒ $1${NC}"; }

validate_core_dependencies() {
    print_info "ðŸ” Validating Core Service Dependencies..."

    # Check for core deployment outputs
    if [ ! -f ".deployment_core_outputs.json" ]; then
        print_error "Core service outputs not found. Deploy core service first."
        return 1
    fi

    if [ ! -f ".deployment_token" ]; then
        print_error "Deployment token not found. Core deployment incomplete."
        return 1
    fi

    # Validate core resources exist
    local core_outputs=$(cat ".deployment_core_outputs.json")
    local storage_name=$(echo "${core_outputs}" | jq -r '.properties.outputs.storageAccountName.value')
    local keyvault_name=$(echo "${core_outputs}" | jq -r '.properties.outputs.keyVaultName.value')

    if [ -z "${storage_name}" ] || [ "${storage_name}" = "null" ]; then
        print_error "Core storage account reference not found"
        return 1
    fi

    if [ -z "${keyvault_name}" ] || [ "${keyvault_name}" = "null" ]; then
        print_error "Core key vault reference not found"
        return 1
    fi

    print_status "Core dependencies validated"
    print_info "  - Storage: ${storage_name}"
    print_info "  - KeyVault: ${keyvault_name}"

    return 0
}

deploy_ml_service() {
    print_info "ðŸ—ï¸  Azure ML Workspace Service Deployment"

    # Load deployment token from core service
    local deployment_token=$(cat ".deployment_token")

    # Deploy ML infrastructure using existing template
    local deployment_output
    if deployment_output=$(az deployment group create \
        --resource-group "${RESOURCE_GROUP}" \
        --template-file "infrastructure/azure-resources-ml-simple.bicep" \
        --parameters "environment=${ENVIRONMENT}" \
                    "location=${AZURE_LOCATION}" \
                    "resourcePrefix=${AZURE_RESOURCE_PREFIX}" \
                    "deploymentToken=${deployment_token}" \
        --name "ml-service-$(date +%Y%m%d-%H%M%S)" \
        --mode Incremental \
        --output json); then

        # Store ML service outputs
        echo "${deployment_output}" > ".deployment_ml_outputs.json"

        # Extract ML service endpoints
        local ml_workspace_name=$(echo "${deployment_output}" | jq -r '.properties.outputs.mlWorkspaceName.value')
        local ml_storage_name=$(echo "${deployment_output}" | jq -r '.properties.outputs.mlStorageAccountName.value')

        # Store for application configuration
        echo "${ml_workspace_name}" > ".deployment_ml_workspace_name"
        echo "${ml_storage_name}" > ".deployment_ml_storage_name"

        print_status "ML Workspace service deployed successfully"
        print_info "ML Service Endpoints:"
        print_info "  - ML Workspace: ${ml_workspace_name}"
        print_info "  - ML Storage: ${ml_storage_name}"

        return 0
    else
        print_error "ML Workspace service deployment failed"
        return 1
    fi
}

validate_ml_service() {
    print_info "ðŸ” Validating ML Service Health..."

    # Validate ML workspace deployment
    local ml_workspace_count=$(az resource list \
        --resource-group "${RESOURCE_GROUP}" \
        --resource-type "Microsoft.MachineLearningServices/workspaces" \
        --query "length(@)" \
        --output tsv 2>/dev/null || echo "0")

    if [ "${ml_workspace_count}" -eq 0 ]; then
        print_error "ML Workspace validation failed"
        return 1
    fi

    print_status "ML service health validation passed"
    return 0
}

main() {
    if ! validate_core_dependencies; then
        exit 1
    fi

    if ! deploy_ml_service; then
        exit 1
    fi

    if ! validate_ml_service; then
        exit 1
    fi

    print_status "ðŸŽ‰ ML Workspace Service Ready"
}

main "$@"
```

### **Service 3: Cosmos DB Deployment**

**Create:** `scripts/deploy-cosmos.sh`

```bash
#!/bin/bash
# Azure Universal RAG - Cosmos DB Service
# Deploys: Cosmos DB Account, Gremlin Database, Knowledge Graph Container

set -euo pipefail

# Load configuration from existing patterns
ENVIRONMENT="${AZURE_ENVIRONMENT:-dev}"
RESOURCE_GROUP="${AZURE_RESOURCE_GROUP:-maintie-rag-rg}"
AZURE_LOCATION="${AZURE_LOCATION:-eastus}"

# Source environment configuration
if [ -f "backend/config/environments/${ENVIRONMENT}.env" ]; then
    source "backend/config/environments/${ENVIRONMENT}.env"
fi

# Color coding from existing codebase
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

print_info() { echo -e "${BLUE}â„¹ï¸  $1${NC}"; }
print_status() { echo -e "${GREEN}âœ… $1${NC}"; }
print_warning() { echo -e "${YELLOW}âš ï¸  $1${NC}"; }
print_error() { echo -e "${RED}âŒ $1${NC}"; }

get_environment_cosmos_config() {
    # Data-driven throughput from environment configuration
    case "${ENVIRONMENT}" in
        "dev") echo "400" ;;
        "staging") echo "800" ;;
        "prod") echo "1600" ;;
        *) echo "400" ;;
    esac
}

deploy_cosmos_service() {
    print_info "ðŸ—ï¸  Azure Cosmos DB Service Deployment"

    # Validate Cosmos DB template exists
    if [ ! -f "infrastructure/azure-resources-cosmos.bicep" ]; then
        print_error "Cosmos DB template not found: infrastructure/azure-resources-cosmos.bicep"
        return 1
    fi

    # Deploy Cosmos DB infrastructure
    local deployment_output
    if deployment_output=$(az deployment group create \
        --resource-group "${RESOURCE_GROUP}" \
        --template-file "infrastructure/azure-resources-cosmos.bicep" \
        --parameters "environment=${ENVIRONMENT}" \
                    "location=${AZURE_LOCATION}" \
                    "resourcePrefix=${AZURE_RESOURCE_PREFIX}" \
        --name "cosmos-service-$(date +%Y%m%d-%H%M%S)" \
        --mode Incremental \
        --output json); then

        # Store Cosmos service outputs
        echo "${deployment_output}" > ".deployment_cosmos_outputs.json"

        # Extract Cosmos service endpoints
        local cosmos_account_name=$(echo "${deployment_output}" | jq -r '.properties.outputs.cosmosAccountName.value')
        local cosmos_endpoint=$(echo "${deployment_output}" | jq -r '.properties.outputs.cosmosEndpoint.value')

        # Store for application configuration
        echo "${cosmos_account_name}" > ".deployment_cosmos_name"
        echo "${cosmos_endpoint}" > ".deployment_cosmos_endpoint"

        print_status "Cosmos DB service deployed successfully"
        print_info "Cosmos Service Configuration:"
        print_info "  - Account: ${cosmos_account_name}"
        print_info "  - Endpoint: ${cosmos_endpoint}"
        print_info "  - Database: universal-rag-db-${ENVIRONMENT}"
        print_info "  - Container: knowledge-graph-${ENVIRONMENT}"
        print_info "  - Throughput: $(get_environment_cosmos_config) RU/s"

        return 0
    else
        print_error "Cosmos DB service deployment failed"
        return 1
    fi
}

validate_cosmos_service() {
    print_info "ðŸ” Validating Cosmos DB Service Health..."

    # Validate Cosmos DB deployment
    local cosmos_count=$(az resource list \
        --resource-group "${RESOURCE_GROUP}" \
        --resource-type "Microsoft.DocumentDB/databaseAccounts" \
        --query "length(@)" \
        --output tsv 2>/dev/null || echo "0")

    if [ "${cosmos_count}" -eq 0 ]; then
        print_error "Cosmos DB validation failed"
        return 1
    fi

    print_status "Cosmos DB service health validation passed"
    return 0
}

main() {
    if ! deploy_cosmos_service; then
        print_warning "Cosmos DB service deployment failed, continuing..."
        return 0  # Non-blocking for now due to regional issues
    fi

    if ! validate_cosmos_service; then
        print_warning "Cosmos DB service validation failed, continuing..."
        return 0  # Non-blocking for now
    fi

    print_status "ðŸŽ‰ Cosmos DB Service Ready"
}

main "$@"
```

### **Service 4: Master Orchestrator**

**Update:** `scripts/azure-deployment-orchestrator.sh`

```bash
#!/bin/bash
# Azure Universal RAG - Enterprise Service Orchestrator
# Coordinates: Core â†’ ML â†’ Cosmos deployment sequence

set -euo pipefail

# Load configuration from existing patterns
ENVIRONMENT="${AZURE_ENVIRONMENT:-dev}"
RESOURCE_GROUP="${AZURE_RESOURCE_GROUP:-maintie-rag-rg}"
AZURE_LOCATION="${AZURE_LOCATION:-eastus}"
DEPLOYMENT_TIMESTAMP=$(date +%Y%m%d-%H%M%S)

# Color coding from existing codebase
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

print_info() { echo -e "${BLUE}â„¹ï¸  $1${NC}"; }
print_status() { echo -e "${GREEN}âœ… $1${NC}"; }
print_warning() { echo -e "${YELLOW}âš ï¸  $1${NC}"; }
print_error() { echo -e "${RED}âŒ $1${NC}"; }
print_header() { echo -e "${BLUE}ðŸ—ï¸  $1${NC}"; }
print_success() { echo -e "${GREEN}ðŸŽ‰ $1${NC}"; }

validate_prerequisites() {
    print_header "Phase 1: Enterprise Prerequisites Validation"

    # Azure CLI authentication
    if ! az account show --output none 2>/dev/null; then
        print_error "Azure CLI not authenticated. Run 'az login'"
        return 1
    fi

    # Resource group validation
    if ! az group show --name "${RESOURCE_GROUP}" --output none 2>/dev/null; then
        print_info "Creating resource group: ${RESOURCE_GROUP}"
        az group create --name "${RESOURCE_GROUP}" --location "${AZURE_LOCATION}"
    fi

    # Service deployment scripts validation
    local required_scripts=("deploy-core.sh" "deploy-ml.sh" "deploy-cosmos.sh")
    for script in "${required_scripts[@]}"; do
        if [ ! -f "scripts/${script}" ]; then
            print_error "Required service script not found: scripts/${script}"
            return 1
        fi
    done

    print_status "Enterprise prerequisites validated"
    return 0
}

deploy_service_tier() {
    local service_name="$1"
    local script_name="$2"
    local is_critical="$3"

    print_header "Phase: ${service_name} Service Deployment"

    if [ -f "scripts/${script_name}" ]; then
        if "./scripts/${script_name}"; then
            print_status "${service_name} service deployment completed"
            return 0
        else
            if [ "${is_critical}" = "true" ]; then
                print_error "${service_name} service deployment failed (critical)"
                return 1
            else
                print_warning "${service_name} service deployment failed (non-critical)"
                return 0
            fi
        fi
    else
        print_error "${service_name} deployment script not found: scripts/${script_name}"
        if [ "${is_critical}" = "true" ]; then
            return 1
        else
            return 0
        fi
    fi
}

generate_service_configuration() {
    print_header "Phase: Service Configuration Generation"

    # Generate environment-specific configuration file
    local config_file="azure-rag-${ENVIRONMENT}-config.env"

    cat > "${config_file}" << EOF
# Azure Universal RAG - Generated Service Configuration
# Generated: $(date)
# Environment: ${ENVIRONMENT}
# Deployment ID: ${DEPLOYMENT_TIMESTAMP}

# Core Service Configuration
AZURE_RESOURCE_GROUP=${RESOURCE_GROUP}
AZURE_ENVIRONMENT=${ENVIRONMENT}
AZURE_LOCATION=${AZURE_LOCATION}
EOF

    # Add core service endpoints if available
    if [ -f ".deployment_storage_name" ]; then
        echo "AZURE_STORAGE_ACCOUNT=$(cat .deployment_storage_name)" >> "${config_file}"
    fi

    if [ -f ".deployment_search_name" ]; then
        echo "AZURE_SEARCH_SERVICE=$(cat .deployment_search_name)" >> "${config_file}"
    fi

    if [ -f ".deployment_keyvault_name" ]; then
        echo "AZURE_KEY_VAULT_NAME=$(cat .deployment_keyvault_name)" >> "${config_file}"
    fi

    # Add ML service endpoints if available
    if [ -f ".deployment_ml_workspace_name" ]; then
        echo "AZURE_ML_WORKSPACE=$(cat .deployment_ml_workspace_name)" >> "${config_file}"
    fi

    # Add Cosmos service endpoints if available
    if [ -f ".deployment_cosmos_name" ]; then
        echo "AZURE_COSMOS_ACCOUNT=$(cat .deployment_cosmos_name)" >> "${config_file}"
    fi

    print_status "Service configuration generated: ${config_file}"
}

cleanup_deployment_artifacts() {
    print_info "Cleaning up deployment artifacts..."

    # Keep essential configuration files, remove temporary ones
    local temp_files=(".deployment_core_outputs.json" ".deployment_ml_outputs.json" ".deployment_cosmos_outputs.json")

    for temp_file in "${temp_files[@]}"; do
        if [ -f "${temp_file}" ]; then
            rm -f "${temp_file}"
        fi
    done

    print_status "Deployment artifacts cleaned"
}

main() {
    print_header "ðŸš€ Azure Universal RAG - Enterprise Service Orchestration"
    print_info "Resource Group: ${RESOURCE_GROUP}"
    print_info "Environment: ${ENVIRONMENT}"
    print_info "Orchestration ID: ${DEPLOYMENT_TIMESTAMP}"

    # Phase 1: Prerequisites
    if ! validate_prerequisites; then
        exit 1
    fi

    # Phase 2: Core Infrastructure (Critical)
    if ! deploy_service_tier "Core Infrastructure" "deploy-core.sh" "true"; then
        exit 1
    fi

    # Phase 3: ML Workspace (Critical)
    if ! deploy_service_tier "ML Workspace" "deploy-ml.sh" "true"; then
        exit 1
    fi

    # Phase 4: Cosmos DB (Non-Critical due to regional issues)
    deploy_service_tier "Cosmos DB" "deploy-cosmos.sh" "false"

    # Phase 5: Service Configuration Generation
    generate_service_configuration

    # Phase 6: Cleanup
    cleanup_deployment_artifacts

    print_success "âœ… Azure Universal RAG Enterprise Deployment Completed"
    print_info "Deployment Summary:"
    print_info "  - Resource Group: ${RESOURCE_GROUP}"
    print_info "  - Environment: ${ENVIRONMENT}"
    print_info "  - Services Deployed: Core, ML Workspace, Cosmos DB"
    print_info "  - Configuration: azure-rag-${ENVIRONMENT}-config.env"
}

main "$@"
```

### **Integration with Existing Infrastructure**

**Update your main deployment script:**

**Modify:** `scripts/enhanced-complete-redeploy.sh`

```bash
#!/bin/bash
# Azure Universal RAG - Enterprise Deployment Entry Point
# Delegates to Service Orchestrator

set -euo pipefail

# Execute the enterprise service orchestrator
exec ./scripts/azure-deployment-orchestrator.sh "$@"
```

### **Enterprise Architecture Benefits**

1. **Service Boundary Isolation**: Each Azure service has independent lifecycle management
2. **Dependency Chain Management**: Clear Core â†’ ML â†’ Cosmos dependency resolution
3. **Enterprise Configuration**: Environment-driven, data-driven configuration propagation
4. **Operational Excellence**: Service-specific health validation and rollback capabilities
5. **DevOps Integration**: Pipeline-friendly service deployment stages

This architecture maintains your existing configuration patterns while providing enterprise-grade service orchestration and dependency management.