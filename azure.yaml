# Azure Developer CLI (azd) configuration for Universal RAG System
name: azure-maintie-rag
metadata:
  template: azure-search-openai-demo@main
  description: "Azure Universal RAG system with knowledge graphs, vector search, and GNN training"

# Services configuration for azd deployment
services:
  backend:
    project: .
    language: python
    host: containerapp
  frontend:
    project: ./frontend
    language: js
    host: containerapp

# Infrastructure configuration
infra:
  provider: bicep
  path: ./infra

# Environment variables that will be set by azd
env:
  # Azure Resource Configuration
  AZURE_LOCATION: westus2
  AZURE_RESOURCE_GROUP_PREFIX: rg-maintie-rag
  
  # Application Configuration
  OPENAI_MODEL_DEPLOYMENT: gpt-4o
  EMBEDDING_MODEL_DEPLOYMENT: text-embedding-ada-002
  SEARCH_INDEX_NAME: maintie-index
  COSMOS_DATABASE_NAME: maintie-rag-db
  COSMOS_GRAPH_NAME: knowledge-graph
  
  # Container Configuration
  BACKEND_PORT: 8000
  
  # Data Pipeline Configuration
  AUTO_POPULATE_DATA: true  # Set to false to skip automated data pipeline

# Deployment hooks
hooks:
  preprovision:
    shell: sh
    run: |
      echo "üèóÔ∏è Preparing Azure Universal RAG deployment..."
      echo "Environment: ${AZURE_ENV_NAME}"
      echo "Location: ${AZURE_LOCATION}"
      
  postprovision:
    shell: sh
    run: |
      echo "‚úÖ Infrastructure provisioned successfully!"
      echo ""
      echo "üîç Checking deployed resources..."
      
      # Get resource group info
      RESOURCE_GROUP="rg-maintie-rag-${AZURE_ENV_NAME}"
      echo "Resource Group: $RESOURCE_GROUP"
      
      # List key resources
      echo ""
      echo "üì¶ Key Resources:"
      az resource list --resource-group "$RESOURCE_GROUP" --query "[].{Name:name, Type:type}" -o table 2>/dev/null || echo "Unable to list resources"
      
      echo ""
      
      # Check if automated data pipeline is enabled
      if [ "${AUTO_POPULATE_DATA:-true}" != "true" ]; then
        echo "‚è≠Ô∏è  Automated data pipeline disabled (AUTO_POPULATE_DATA=false)"
        echo "üí° Run 'make dataflow-full' manually to populate data"
        echo ""
        echo "‚úÖ Infrastructure ready for manual data population"
        exit 0
      fi
      
      echo "üöÄ Option 2: Async Model Deployment - Infrastructure ready for REAL data pipeline"
      echo ""
      echo "‚ö° REAL DATA PIPELINE EXECUTION INSTRUCTIONS:"
      echo "   Infrastructure is deployed and ready for REAL data processing"
      echo "   Run the following command to execute REAL data pipeline:"
      echo ""
      echo "   make dataflow-full"
      echo ""
      echo "   This will execute REAL Azure data processing with:"
      echo "   ‚úÖ REAL Azure services authentication"
      echo "   ‚úÖ REAL data from data/raw/ directory" 
      echo "   ‚úÖ REAL GNN model training and deployment"
      echo "   ‚úÖ REAL tri-modal search (Vector + Graph + GNN)"
      echo "   ‚úÖ NO fallback, NO placeholders, NO fake success"
      echo ""
      echo "   After pipeline completion, the system will have:"
      echo "   - All documents uploaded to Azure Storage"
      echo "   - Vector embeddings in Azure Cognitive Search"
      echo "   - Knowledge graph in Cosmos DB"
      echo "   - GNN models trained and deployed to Azure ML"
      echo "   - Complete tri-modal RAG system operational"
      
  postdeploy:
    shell: sh
    run: |
      echo "‚úÖ Deployment complete!"
      echo ""
      echo "üîó Getting deployment URLs..."
      
      # Run our working URL script
      if [ -f "./scripts/show-deployment-urls.sh" ]; then
        ./scripts/show-deployment-urls.sh
      else
        echo "üìç Use this command to get URLs: ./scripts/show-deployment-urls.sh"
      fi
      
      echo ""
      echo "üìä Environment: ${AZURE_ENV_NAME}"
      echo "üí° Chat interface is ready for testing!"