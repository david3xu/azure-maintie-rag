#!/usr/bin/env python3
"""
Universal Domain Intelligence Demo - Zero Hardcoded Values
=========================================================

Demonstrates how the universal agent discovers domain characteristics
from actual data without any predetermined assumptions.
"""

import sys
import asyncio
from pathlib import Path

# Add root directory to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

# Import universal domain intelligence
from agents.domain_intelligence.agent import (
    UniversalDomainDeps, 
    run_universal_domain_analysis
)

def demonstrate_universality():
    """Show how the universal agent has ZERO hardcoded domain knowledge"""
    
    print("ğŸŒ Universal Domain Intelligence - Zero Hardcoded Values")
    print("=====================================================")
    
    print("\nâœ… What makes this TRULY universal:")
    print("   â€¢ NO predetermined domain types (programming, business, etc.)")
    print("   â€¢ NO hardcoded keywords or entity types") 
    print("   â€¢ NO fixed thresholds or scoring rules")
    print("   â€¢ NO language assumptions")
    print("   â€¢ NO content structure assumptions")
    
    print("\nğŸ” Instead, it discovers:")
    print("   â€¢ Domain characteristics from vocabulary patterns")
    print("   â€¢ Content structure from actual document analysis")
    print("   â€¢ Processing parameters from measured complexity")
    print("   â€¢ Thresholds from content distribution statistics")
    print("   â€¢ Configuration from discovered patterns")
    
    print("\nğŸ“Š Data-Driven Analysis Process:")
    print("   1. Statistical analysis of actual content")
    print("   2. Vocabulary richness and technical density measurement")
    print("   3. Structural pattern discovery")
    print("   4. Adaptive configuration generation")
    print("   5. Dynamic signature creation from characteristics")

async def run_universal_demo():
    """Run the universal analysis on real data"""
    
    # Test with actual data directory
    deps = UniversalDomainDeps(
        data_directory="/workspace/azure-maintie-rag/data/raw",
        max_files_to_analyze=30,  # Reasonable limit
        min_content_length=50,
        enable_multilingual=True
    )
    
    print(f"\nğŸš€ Running Universal Analysis on Real Data")
    print(f"==========================================")
    print(f"ğŸ“‚ Data source: {deps.data_directory}")
    print(f"ğŸ“Š Analysis limit: {deps.max_files_to_analyze} files")
    print(f"ğŸŒ Multilingual support: {'âœ…' if deps.enable_multilingual else 'âŒ'}")
    
    # Run the universal analysis
    try:
        analysis = await run_universal_domain_analysis(deps)
        
        print(f"\nğŸ“ˆ Universal Analysis Results:")
        print(f"===============================")
        print(f"ğŸ·ï¸  Domain Signature: {analysis.domain_signature}")
        print(f"ğŸ¯ Confidence: {analysis.content_type_confidence:.2f}")
        print(f"â±ï¸  Processing Time: {analysis.processing_time:.2f}s")
        print(f"ğŸ”’ Reliability: {analysis.analysis_reliability:.2f}")
        
        print(f"\nğŸ“Š Discovered Content Characteristics:")
        print(f"======================================")
        cc = analysis.characteristics
        print(f"   Documents Analyzed: {cc.document_count}")
        print(f"   Avg Document Length: {cc.avg_document_length:,} chars")
        print(f"   Vocabulary Richness: {cc.vocabulary_richness:.3f}")
        print(f"   Technical Density: {cc.technical_vocabulary_ratio:.3f}")
        print(f"   Sentence Complexity: {cc.sentence_complexity:.1f} words/sentence")
        print(f"   Lexical Diversity: {cc.lexical_diversity:.3f}")
        
        if cc.most_frequent_terms:
            print(f"   Most Frequent Terms: {cc.most_frequent_terms[:5]}")
        
        if cc.content_patterns:
            print(f"   Content Patterns: {cc.content_patterns}")
        
        print(f"\nâš™ï¸  Adaptive Processing Configuration:")
        print(f"=====================================")
        pc = analysis.processing_config
        print(f"   Optimal Chunk Size: {pc.optimal_chunk_size}")
        print(f"   Chunk Overlap: {pc.chunk_overlap_ratio:.1%}")
        print(f"   Entity Threshold: {pc.entity_confidence_threshold:.2f}")
        print(f"   Vector Search Weight: {pc.vector_search_weight:.1%}")
        print(f"   Graph Search Weight: {pc.graph_search_weight:.1%}")
        print(f"   Expected Quality: {pc.expected_extraction_quality:.1%}")
        print(f"   Processing Complexity: {pc.processing_complexity}")
        
        print(f"\nğŸ’¡ Data-Driven Insights:")
        print(f"========================")
        for i, insight in enumerate(analysis.key_insights, 1):
            print(f"   {i}. {insight}")
        
        print(f"\nğŸ¯ Adaptation Recommendations:")
        print(f"==============================")
        for i, rec in enumerate(analysis.adaptation_recommendations, 1):
            print(f"   {i}. {rec}")
        
        print(f"\nğŸ”— How This Drives Other Agents:")
        print(f"=================================")
        print(f"   ğŸ§  Knowledge Extraction Agent gets:")
        print(f"      â€¢ Chunk size: {pc.optimal_chunk_size}")
        print(f"      â€¢ Entity threshold: {pc.entity_confidence_threshold}")
        print(f"      â€¢ Content patterns: {cc.content_patterns}")
        
        print(f"   ğŸ” Universal Search Agent gets:")
        print(f"      â€¢ Vector weight: {pc.vector_search_weight}")
        print(f"      â€¢ Graph weight: {pc.graph_search_weight}")
        print(f"      â€¢ Domain terms: {cc.most_frequent_terms[:3] if cc.most_frequent_terms else 'None'}")
        
        print(f"   ğŸ›ï¸  Orchestrator gets:")
        print(f"      â€¢ Processing complexity: {pc.processing_complexity}")
        print(f"      â€¢ Expected quality: {pc.expected_extraction_quality}")
        print(f"      â€¢ Reliability score: {analysis.analysis_reliability}")
        
        return analysis
        
    except Exception as e:
        print(f"âŒ Analysis failed: {e}")
        return None

def compare_approaches():
    """Compare universal vs predetermined approaches"""
    
    print(f"\nğŸ“Š Universal vs Predetermined Comparison")
    print(f"=======================================")
    
    print(f"ğŸ“‰ Predetermined Approach Problems:")
    print(f"   âŒ Fixed domain types (programming, business, etc.)")
    print(f"   âŒ Hardcoded keywords and patterns")
    print(f"   âŒ Static configuration values")
    print(f"   âŒ Language-specific assumptions")
    print(f"   âŒ Fails on unknown/mixed domains")
    print(f"   âŒ Not adaptable to new content types")
    
    print(f"\nğŸ“ˆ Universal Approach Benefits:")
    print(f"   âœ… Learns from actual content characteristics")
    print(f"   âœ… Adapts to ANY domain or content type")
    print(f"   âœ… No hardcoded assumptions")
    print(f"   âœ… Language-agnostic analysis")
    print(f"   âœ… Handles mixed/unknown domains gracefully")
    print(f"   âœ… Generates optimal configurations dynamically")
    print(f"   âœ… Maintains true 'universal' RAG principles")
    
    print(f"\nğŸ¯ Result:")
    print(f"   The universal agent preserves the 'universal' nature of your RAG")
    print(f"   system while still providing intelligent domain-specific optimization.")

async def main():
    """Run the complete universal domain intelligence demo"""
    
    # Show the universality principles
    demonstrate_universality()
    
    # Run actual analysis if data directory exists
    data_path = Path("/workspace/azure-maintie-rag/data/raw")
    if data_path.exists():
        analysis = await run_universal_demo()
        if analysis:
            print(f"\nâœ… Universal analysis completed successfully!")
        else:
            print(f"\nâš ï¸  Analysis completed with warnings")
    else:
        print(f"\nâš ï¸  Data directory not found: {data_path}")
        print(f"   The universal agent will analyze any content you provide")
    
    # Show comparison with predetermined approaches
    compare_approaches()
    
    print(f"\nğŸŒ Universal RAG Principles Maintained!")
    print(f"======================================")
    print(f"Your system remains truly universal while gaining intelligent")
    print(f"domain-specific optimization through data-driven analysis.")

if __name__ == "__main__":
    asyncio.run(main())